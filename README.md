# Intro
This purpose of this repository is to home a list of papers I deem important for the areas I am interested in. I should have started this repo right when I started reading into deep learning. Instead I will now add the papers I have read in the past as I come across them again. Further I extend this list with topics I am researching.

## Computer Vision

### Classification

+ LeNet: [LeCun, Y., Bottou, L., Bengio, Y., & Haffner, P. (1998). Gradient-based learning applied to document recognition.](http://vision.stanford.edu/cs598_spring07/papers/Lecun98.pdf)
+ VGG: [Simonyan, K., & Zisserman, A. (2014). Very deep convolutional networks for large-scale image recognition.](https://arxiv.org/abs/1409.1556)
+ ResNet: [He, K., Zhang, X., Ren, S., & Sun, J. (2016). Deep residual learning for image recognition.](https://arxiv.org/abs/1512.03385)

### Object Detection
+ R-CNN: [Girshick, R., Donahue, J., Darrell, T., & Malik, J. (2014). Rich feature hierarchies for accurate object detection and semantic segmentation.](https://arxiv.org/abs/1311.2524)
+ SSD: [Liu, W., Anguelov, D., Erhan, D., Szegedy, C., Reed, S., Fu, C. Y., & Berg, A. C. (2016, October). Ssd: Single shot multibox detector.](https://arxiv.org/abs/1512.02325)
+ Yolo v1:[Redmon, J., Divvala, S., Girshick, R., & Farhadi, A. (2016). You only look once: Unified, real-time object detection.](https://arxiv.org/abs/1506.02640)
+ RetinaNet / Focal Loss: [Lin, T. Y., Goyal, P., Girshick, R., He, K., & Dollár, P. (2017). Focal loss for dense object detection.](https://arxiv.org/abs/1708.02002)

## Neural Network Pruning
+ [Han, S., Pool, J., Tran, J., & Dally, W. J. (2015). Learning both weights and connections for efficient neural networks.](https://arxiv.org/abs/1506.02626)
+ [Zhang, T., Ye, S., Zhang, K., Tang, J., Wen, W., Fardad, M., & Wang, Y. (2018). A systematic dnn weight pruning framework using alternating direction method of multipliers.](https://arxiv.org/abs/1802.05747)
+ [Frankle, J., & Carbin, M. (2018). The lottery ticket hypothesis: Finding sparse, trainable neural networks.](https://arxiv.org/abs/1803.03635)
+ [Blalock, D., Ortiz, J. J. G., Frankle, J., & Guttag, J. (2020). What is the state of neural network pruning?](https://arxiv.org/abs/2003.03033)
+ [Paganini, M., & Forde, J. (2020). On iterative neural network pruning, reinitialization, and the similarity of masks.](https://arxiv.org/abs/2001.05050)

## Adversarial Deep Learning
+ Intro / FGSM: [Szegedy, C., Zaremba, W., Sutskever, I., Bruna, J., Erhan, D., Goodfellow, I., & Fergus, R. (2013). Intriguing properties of neural networks.](https://arxiv.org/abs/1312.6199)
+ Adversarial Training: [Goodfellow, I. J., Shlens, J., & Szegedy, C. (2014). Explaining and harnessing adversarial examples.](https://arxiv.org/abs/1412.6572.pdf)
+ PGD / Adversarial Training: [Madry, A., Makelov, A., Schmidt, L., Tsipras, D., & Vladu, A. (2017). Towards deep learning models resistant to adversarial attacks.] (https://arxiv.org/abs/1706.06083)
+ Free: [Shafahi, A., Najibi, M., Ghiasi, A., Xu, Z., Dickerson, J., Studer, C., ... & Goldstein, T. (2019). Adversarial training for free!.](https://arxiv.org/abs/1904.12843)
+ Carlini & Wagner Attacks: [Carlini, N., & Wagner, D. (2017, May). Towards evaluating the robustness of neural networks.](https://arxiv.org/abs/1608.04644)
+ Brendel & Betghe Attacks: [Brendel, W., Rauber, J., Kümmerer, M., Ustyuzhaninov, I., & Bethge, M. (2019). Accurate, reliable and fast robustness evaluation.](https://arxiv.org/abs/1907.01003)
+ Brendel & Betghe Black Box Attack: [Brendel, W., Rauber, J., & Bethge, M. (2017). Decision-based adversarial attacks: Reliable attacks against black-box machine learning models](https://arxiv.org/abs/1712.04248)
+ Evaluation Standards: [Carlini, N., Athalye, A., Papernot, N., Brendel, W., Rauber, J., Tsipras, D., ... & Kurakin, A. (2019). On evaluating adversarial robustness.](https://arxiv.org/abs/1902.06705)

