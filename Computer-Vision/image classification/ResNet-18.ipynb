{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import time\n",
    "import torch.optim as optim\n",
    "from data import load_imagenette, load_torchvision_dataset\n",
    "\n",
    "\n",
    "if torch.cuda.is_available() == True:\n",
    "    device = torch.device(\"cuda:0\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "print(device)\n",
    "dtype = torch.float32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-04 14:02:18.896316: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.layers import Dense, Flatten, Conv2D, BatchNormalization, Dropout\n",
    "from tensorflow.keras import regularizers\n",
    "\n",
    "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
    "\n",
    "import time\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResBlock(nn.Module):\n",
    "    \"\"\" ResBlock made from masked Layers\"\"\"\n",
    "    def __init__(self, input_channels, output_channels, padding=0 , stride=1, kernel_size=3):\n",
    "        super(ResBlock, self).__init__()\n",
    "        self.s = stride\n",
    "        self.bn1 = nn.BatchNorm2d(input_channels)\n",
    "        self.c1 = nn.Conv2d(input_channels, output_channels, kernel_size, padding=padding, stride=self.s, bias=False)\n",
    "        #self.c1 = MaskedConvLayer((output_channels, input_channels, filter_size, filter_size), padding=padding, bias=False, stride=self.s)\n",
    "        self.bn2 = nn.BatchNorm2d(output_channels)\n",
    "        self.c2 = nn.Conv2d(output_channels, output_channels, kernel_size, padding=padding, stride=1, bias=False)\n",
    "        #self.c2 = MaskedConvLayer((output_channels, output_channels, filter_size, filter_size), padding=padding, bias=False, stride=1)\n",
    "        if self.s == 2:\n",
    "            #self.c3 = MaskedConvLayer((output_channels, input_channels, 1,1),padding=0, bias=False, stride=self.s)\n",
    "            self.c3 = nn.Conv2d(input_channels, output_channels, 1, padding=0, stride=self.s, bias=False)\n",
    "            \n",
    "    def forward(self, inputs):\n",
    "        shortcut = inputs\n",
    "        x = self.c1(F.relu(self.bn1(inputs)))\n",
    "        x = self.c2(F.relu(self.bn2(x)))\n",
    "        if self.s == 2:\n",
    "            shortcut = self.c3(shortcut)\n",
    "        x = torch.add(x, shortcut)\n",
    "        return x\n",
    "\n",
    "class CifarResNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CifarResNet, self).__init__()\n",
    "        self.c1 = nn.Conv2d(3,64,3,padding=(1,1),bias=False, stride=1)\n",
    "        self.r1 = ResBlock(64,64,padding=1)\n",
    "        self.r2 = ResBlock(64,64,padding=1)\n",
    "        self.r3 = ResBlock(64,128,stride=2,padding=1)\n",
    "        self.r4 = ResBlock(128,128,padding=1)\n",
    "        self.r5 = ResBlock(128,256,stride=2,padding=1)\n",
    "        self.r6 = ResBlock(256,256,padding=1)\n",
    "        self.r7 = ResBlock(256,512,stride=2,padding=1)\n",
    "        self.r8 = ResBlock(512,512,padding=1)\n",
    "        self.p2 = nn.AvgPool2d(4)\n",
    "        self.d1 = nn.Linear(512,10)\n",
    "        \n",
    "    def forward(self, inputs):\n",
    "        x = self.c1(inputs)\n",
    "        x = self.r1(x)\n",
    "        x = self.r2(x)\n",
    "        x = self.r3(x)\n",
    "        x = self.r4(x)\n",
    "        x = self.r5(x)\n",
    "        x = self.r6(x)\n",
    "        x = self.r7(x)\n",
    "        #x = self.r8(x)\n",
    "        x = self.p2(x)\n",
    "        x = x.view(x.shape[0], x.shape[1])\n",
    "        x = self.d1(x)\n",
    "        return (x)\n",
    "    \n",
    "class ImageNetResNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ImageNetResNet, self).__init__()\n",
    "        #self.c1 = MaskedConvLayer((64, 3, 7, 7), padding=(3,3),bias=False, stride=2)\n",
    "        self.c1 = nn.Conv2d(3,64,7, padding=(3,3),bias=False, stride=2)\n",
    "        self.p1 = nn.MaxPool2d((3,3), stride=(2,2), padding=(1))\n",
    "        self.r1 = ResBlock(64,64,padding=1)\n",
    "        self.r2 = ResBlock(64,64,padding=1)\n",
    "        self.r3 = ResBlock(64,128,stride=2,padding=1)\n",
    "        self.r4 = ResBlock(128,128,padding=1)\n",
    "        self.r5 = ResBlock(128,256,stride=2,padding=1)\n",
    "        self.r6 = ResBlock(256,256,padding=1)\n",
    "        self.r7 = ResBlock(256,512,stride=2,padding=1)\n",
    "        self.r8 = ResBlock(512,512,padding=1)\n",
    "        self.p2 = nn.AvgPool2d(7)\n",
    "        self.d1 = nn.Linear(512,10)\n",
    "    \n",
    "    def forward(self, inputs):\n",
    "        x = self.c1(inputs)\n",
    "        x = self.p1(x)\n",
    "        x = self.r1(x)\n",
    "        x = self.r2(x)\n",
    "        x = self.r3(x)\n",
    "        x = self.r4(x)\n",
    "        x = self.r5(x)\n",
    "        x = self.r6(x)\n",
    "        x = self.r7(x)\n",
    "        x = self.r8(x)\n",
    "        x = self.p2(x)\n",
    "        x = x.view(x.shape[0], x.shape[1])\n",
    "        x = self.d1(x)\n",
    "        return (x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'm' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_26772/802037075.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'm' is not defined"
     ]
    }
   ],
   "source": [
    "sum([p.numel() for p in m.parameters()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0784,  0.0841, -0.0207,  0.0004,  0.0868,  0.2435,  0.0250, -0.2190,\n",
       "          0.2123,  0.0037]], device='cuda:0', grad_fn=<AddmmBackward>)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = CifarResNet().to(device)\n",
    "m(torch.randn((1,3,32,32)).to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.2038,  0.1521, -0.0023, -0.2033,  0.3244,  0.0647,  0.2296,  0.2677,\n",
       "         -0.1040, -0.0898]], device='cuda:0', grad_fn=<AddmmBackward>)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = ImageNetResNet().to(device)\n",
    "m(torch.randn((1,3,224,224)).to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = '/home/florian/data/imagenette2'\n",
    "train_dl, val_dl = load_imagenette(PATH, 128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "train_dl, val_dl = load_torchvision_dataset('CIFAR10', data_augmentation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,     1] loss: 2.30916, train_accuracy: 11.52, time: 0.24\n",
      "[1,    11] loss: 2.72165, train_accuracy: 15.23, time: 0.21\n",
      "[1,    21] loss: 2.14381, train_accuracy: 19.34, time: 0.21\n",
      "[1,    31] loss: 2.11411, train_accuracy: 24.02, time: 0.22\n",
      "[1,    41] loss: 1.96324, train_accuracy: 28.52, time: 0.21\n",
      "[1,    51] loss: 1.94638, train_accuracy: 31.25, time: 0.21\n",
      "[1,    61] loss: 1.84912, train_accuracy: 25.39, time: 0.21\n",
      "[1,    71] loss: 1.74550, train_accuracy: 32.62, time: 0.22\n",
      "[1,    81] loss: 1.75294, train_accuracy: 35.55, time: 0.21\n",
      "[1,    91] loss: 1.84840, train_accuracy: 29.69, time: 0.21\n",
      "duration: 21 s - train loss: 2.19618 - train accuracy: 25.95 - validation loss: 1.77 - validation accuracy: 33.61 \n",
      "[2,     1] loss: 1.82785, train_accuracy: 29.49, time: 0.22\n",
      "[2,    11] loss: 1.74302, train_accuracy: 33.01, time: 0.22\n",
      "[2,    21] loss: 1.69170, train_accuracy: 34.57, time: 0.21\n",
      "[2,    31] loss: 1.64378, train_accuracy: 38.87, time: 0.22\n",
      "[2,    41] loss: 1.64039, train_accuracy: 37.30, time: 0.21\n",
      "[2,    51] loss: 1.54417, train_accuracy: 43.75, time: 0.22\n",
      "[2,    61] loss: 1.52036, train_accuracy: 44.14, time: 0.22\n",
      "[2,    71] loss: 1.53474, train_accuracy: 42.19, time: 0.21\n",
      "[2,    81] loss: 1.47466, train_accuracy: 45.90, time: 0.22\n",
      "[2,    91] loss: 1.39574, train_accuracy: 50.00, time: 0.21\n",
      "duration: 21 s - train loss: 1.59513 - train accuracy: 40.96 - validation loss: 1.64 - validation accuracy: 42.39 \n",
      "[3,     1] loss: 1.53501, train_accuracy: 42.97, time: 0.22\n",
      "[3,    11] loss: 1.42069, train_accuracy: 46.88, time: 0.21\n",
      "[3,    21] loss: 1.43692, train_accuracy: 47.27, time: 0.21\n",
      "[3,    31] loss: 1.43685, train_accuracy: 46.09, time: 0.21\n",
      "[3,    41] loss: 1.38041, train_accuracy: 50.98, time: 0.22\n",
      "[3,    51] loss: 1.29231, train_accuracy: 53.32, time: 0.22\n",
      "[3,    61] loss: 1.32460, train_accuracy: 54.10, time: 0.22\n",
      "[3,    71] loss: 1.42997, train_accuracy: 50.78, time: 0.22\n",
      "[3,    81] loss: 1.32318, train_accuracy: 52.15, time: 0.22\n",
      "[3,    91] loss: 1.18171, train_accuracy: 59.38, time: 0.21\n",
      "duration: 21 s - train loss: 1.34353 - train accuracy: 51.02 - validation loss: 1.62 - validation accuracy: 47.01 \n",
      "[4,     1] loss: 1.16092, train_accuracy: 56.25, time: 0.21\n",
      "[4,    11] loss: 1.12361, train_accuracy: 59.96, time: 0.22\n",
      "[4,    21] loss: 1.31266, train_accuracy: 56.25, time: 0.22\n",
      "[4,    31] loss: 1.05694, train_accuracy: 60.74, time: 0.21\n",
      "[4,    41] loss: 1.19635, train_accuracy: 58.79, time: 0.22\n",
      "[4,    51] loss: 1.15231, train_accuracy: 58.79, time: 0.21\n",
      "[4,    61] loss: 1.05737, train_accuracy: 63.28, time: 0.21\n",
      "[4,    71] loss: 1.15358, train_accuracy: 58.20, time: 0.21\n",
      "[4,    81] loss: 1.25593, train_accuracy: 55.08, time: 0.22\n",
      "[4,    91] loss: 1.10316, train_accuracy: 60.35, time: 0.21\n",
      "duration: 21 s - train loss: 1.15294 - train accuracy: 58.99 - validation loss: 1.77 - validation accuracy: 46.16 \n",
      "[5,     1] loss: 1.08838, train_accuracy: 60.94, time: 0.22\n",
      "[5,    11] loss: 1.15419, train_accuracy: 60.35, time: 0.22\n",
      "[5,    21] loss: 0.96540, train_accuracy: 65.04, time: 0.21\n",
      "[5,    31] loss: 1.04621, train_accuracy: 63.09, time: 0.22\n",
      "[5,    41] loss: 1.03491, train_accuracy: 63.67, time: 0.21\n",
      "[5,    51] loss: 1.04512, train_accuracy: 60.35, time: 0.22\n",
      "[5,    61] loss: 1.03710, train_accuracy: 61.33, time: 0.22\n",
      "[5,    71] loss: 0.97745, train_accuracy: 65.23, time: 0.22\n",
      "[5,    81] loss: 0.93539, train_accuracy: 66.99, time: 0.22\n",
      "[5,    91] loss: 0.98978, train_accuracy: 65.62, time: 0.21\n",
      "duration: 21 s - train loss: 1.01114 - train accuracy: 64.04 - validation loss: 1.21 - validation accuracy: 60.79 \n",
      "[6,     1] loss: 0.91124, train_accuracy: 68.55, time: 0.22\n",
      "[6,    11] loss: 0.98517, train_accuracy: 65.04, time: 0.21\n",
      "[6,    21] loss: 0.97006, train_accuracy: 64.84, time: 0.21\n",
      "[6,    31] loss: 0.93854, train_accuracy: 66.80, time: 0.21\n",
      "[6,    41] loss: 0.92494, train_accuracy: 66.41, time: 0.22\n",
      "[6,    51] loss: 0.92677, train_accuracy: 67.19, time: 0.22\n",
      "[6,    61] loss: 0.95260, train_accuracy: 66.02, time: 0.21\n",
      "[6,    71] loss: 0.92996, train_accuracy: 66.99, time: 0.22\n",
      "[6,    81] loss: 0.90802, train_accuracy: 67.97, time: 0.21\n",
      "[6,    91] loss: 0.86529, train_accuracy: 68.95, time: 0.22\n",
      "duration: 21 s - train loss: 0.90495 - train accuracy: 67.83 - validation loss: 1.16 - validation accuracy: 64.18 \n",
      "[7,     1] loss: 0.81212, train_accuracy: 72.66, time: 0.22\n",
      "[7,    11] loss: 0.75478, train_accuracy: 73.24, time: 0.22\n",
      "[7,    21] loss: 0.86126, train_accuracy: 71.09, time: 0.22\n",
      "[7,    31] loss: 0.75424, train_accuracy: 74.02, time: 0.21\n",
      "[7,    41] loss: 0.82446, train_accuracy: 70.90, time: 0.21\n",
      "[7,    51] loss: 0.62289, train_accuracy: 77.93, time: 0.21\n",
      "[7,    61] loss: 0.78466, train_accuracy: 72.66, time: 0.21\n",
      "[7,    71] loss: 0.81023, train_accuracy: 69.92, time: 0.21\n",
      "[7,    81] loss: 0.80727, train_accuracy: 72.66, time: 0.22\n",
      "[7,    91] loss: 0.84002, train_accuracy: 72.07, time: 0.21\n",
      "duration: 21 s - train loss: 0.81181 - train accuracy: 71.49 - validation loss: 1.26 - validation accuracy: 62.94 \n",
      "[8,     1] loss: 0.86360, train_accuracy: 69.73, time: 0.22\n",
      "[8,    11] loss: 0.79387, train_accuracy: 72.85, time: 0.21\n",
      "[8,    21] loss: 0.72896, train_accuracy: 74.22, time: 0.22\n",
      "[8,    31] loss: 0.75722, train_accuracy: 72.85, time: 0.22\n",
      "[8,    41] loss: 0.74728, train_accuracy: 72.66, time: 0.22\n",
      "[8,    51] loss: 0.73494, train_accuracy: 74.80, time: 0.22\n",
      "[8,    61] loss: 0.61843, train_accuracy: 78.71, time: 0.22\n",
      "[8,    71] loss: 0.73758, train_accuracy: 76.95, time: 0.22\n",
      "[8,    81] loss: 0.78506, train_accuracy: 74.02, time: 0.22\n",
      "[8,    91] loss: 0.77240, train_accuracy: 73.83, time: 0.22\n",
      "duration: 21 s - train loss: 0.73300 - train accuracy: 74.47 - validation loss: 0.97 - validation accuracy: 68.93 \n",
      "[9,     1] loss: 0.68509, train_accuracy: 76.76, time: 0.22\n",
      "[9,    11] loss: 0.63433, train_accuracy: 77.93, time: 0.22\n",
      "[9,    21] loss: 0.64879, train_accuracy: 76.17, time: 0.22\n",
      "[9,    31] loss: 0.59941, train_accuracy: 77.34, time: 0.22\n",
      "[9,    41] loss: 0.72065, train_accuracy: 74.61, time: 0.21\n",
      "[9,    51] loss: 0.64572, train_accuracy: 77.15, time: 0.22\n",
      "[9,    61] loss: 0.75434, train_accuracy: 74.61, time: 0.21\n",
      "[9,    71] loss: 0.60119, train_accuracy: 81.05, time: 0.22\n",
      "[9,    81] loss: 0.66801, train_accuracy: 78.52, time: 0.22\n",
      "[9,    91] loss: 0.71117, train_accuracy: 75.78, time: 0.23\n",
      "duration: 21 s - train loss: 0.66645 - train accuracy: 76.83 - validation loss: 0.91 - validation accuracy: 70.50 \n",
      "[10,     1] loss: 0.56047, train_accuracy: 80.47, time: 0.22\n",
      "[10,    11] loss: 0.59345, train_accuracy: 80.08, time: 0.21\n",
      "[10,    21] loss: 0.61743, train_accuracy: 76.37, time: 0.21\n",
      "[10,    31] loss: 0.71577, train_accuracy: 75.00, time: 0.22\n",
      "[10,    41] loss: 0.63475, train_accuracy: 78.71, time: 0.22\n",
      "[10,    51] loss: 0.60867, train_accuracy: 78.32, time: 0.22\n",
      "[10,    61] loss: 0.58098, train_accuracy: 80.66, time: 0.22\n",
      "[10,    71] loss: 0.62014, train_accuracy: 76.17, time: 0.22\n",
      "[10,    81] loss: 0.68642, train_accuracy: 77.93, time: 0.21\n",
      "[10,    91] loss: 0.55697, train_accuracy: 80.86, time: 0.21\n",
      "duration: 21 s - train loss: 0.61271 - train accuracy: 78.60 - validation loss: 1.28 - validation accuracy: 66.98 \n",
      "[11,     1] loss: 0.61098, train_accuracy: 77.73, time: 0.22\n",
      "[11,    11] loss: 0.54511, train_accuracy: 81.45, time: 0.22\n",
      "[11,    21] loss: 0.64929, train_accuracy: 76.56, time: 0.22\n",
      "[11,    31] loss: 0.52549, train_accuracy: 81.45, time: 0.21\n",
      "[11,    41] loss: 0.59602, train_accuracy: 79.49, time: 0.22\n",
      "[11,    51] loss: 0.62720, train_accuracy: 80.86, time: 0.22\n",
      "[11,    61] loss: 0.57532, train_accuracy: 79.88, time: 0.22\n",
      "[11,    71] loss: 0.55810, train_accuracy: 81.05, time: 0.21\n",
      "[11,    81] loss: 0.55677, train_accuracy: 80.66, time: 0.21\n",
      "[11,    91] loss: 0.53374, train_accuracy: 80.86, time: 0.21\n",
      "duration: 21 s - train loss: 0.56947 - train accuracy: 80.21 - validation loss: 0.80 - validation accuracy: 75.87 \n",
      "[12,     1] loss: 0.53923, train_accuracy: 82.42, time: 0.22\n",
      "[12,    11] loss: 0.48341, train_accuracy: 81.84, time: 0.21\n",
      "[12,    21] loss: 0.55703, train_accuracy: 78.91, time: 0.22\n",
      "[12,    31] loss: 0.49113, train_accuracy: 83.01, time: 0.22\n",
      "[12,    41] loss: 0.53316, train_accuracy: 80.47, time: 0.22\n",
      "[12,    51] loss: 0.49362, train_accuracy: 81.25, time: 0.22\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12,    61] loss: 0.49532, train_accuracy: 84.96, time: 0.22\n",
      "[12,    71] loss: 0.51346, train_accuracy: 82.23, time: 0.22\n",
      "[12,    81] loss: 0.51108, train_accuracy: 79.88, time: 0.22\n",
      "[12,    91] loss: 0.51293, train_accuracy: 83.40, time: 0.21\n",
      "duration: 21 s - train loss: 0.52309 - train accuracy: 81.94 - validation loss: 0.96 - validation accuracy: 71.59 \n",
      "[13,     1] loss: 0.51331, train_accuracy: 83.40, time: 0.21\n",
      "[13,    11] loss: 0.49318, train_accuracy: 82.62, time: 0.21\n",
      "[13,    21] loss: 0.46806, train_accuracy: 82.03, time: 0.21\n",
      "[13,    31] loss: 0.45059, train_accuracy: 84.57, time: 0.21\n",
      "[13,    41] loss: 0.46364, train_accuracy: 85.74, time: 0.21\n",
      "[13,    51] loss: 0.46378, train_accuracy: 82.62, time: 0.22\n",
      "[13,    61] loss: 0.53060, train_accuracy: 81.05, time: 0.22\n",
      "[13,    71] loss: 0.47208, train_accuracy: 83.20, time: 0.22\n",
      "[13,    81] loss: 0.59908, train_accuracy: 79.49, time: 0.21\n",
      "[13,    91] loss: 0.50819, train_accuracy: 82.81, time: 0.22\n",
      "duration: 21 s - train loss: 0.48999 - train accuracy: 83.14 - validation loss: 0.67 - validation accuracy: 78.49 \n",
      "[14,     1] loss: 0.45213, train_accuracy: 85.94, time: 0.22\n",
      "[14,    11] loss: 0.46142, train_accuracy: 85.16, time: 0.22\n",
      "[14,    21] loss: 0.39439, train_accuracy: 86.52, time: 0.22\n",
      "[14,    31] loss: 0.49329, train_accuracy: 84.38, time: 0.22\n",
      "[14,    41] loss: 0.39892, train_accuracy: 86.91, time: 0.21\n",
      "[14,    51] loss: 0.50741, train_accuracy: 83.40, time: 0.22\n",
      "[14,    61] loss: 0.42657, train_accuracy: 85.35, time: 0.22\n",
      "[14,    71] loss: 0.37842, train_accuracy: 86.91, time: 0.22\n",
      "[14,    81] loss: 0.52759, train_accuracy: 81.84, time: 0.22\n",
      "[14,    91] loss: 0.49865, train_accuracy: 83.01, time: 0.22\n",
      "duration: 21 s - train loss: 0.46831 - train accuracy: 83.84 - validation loss: 1.12 - validation accuracy: 70.15 \n",
      "[15,     1] loss: 0.40034, train_accuracy: 86.33, time: 0.22\n",
      "[15,    11] loss: 0.47033, train_accuracy: 83.01, time: 0.22\n",
      "[15,    21] loss: 0.45055, train_accuracy: 84.57, time: 0.21\n",
      "[15,    31] loss: 0.46836, train_accuracy: 83.40, time: 0.22\n",
      "[15,    41] loss: 0.47237, train_accuracy: 81.84, time: 0.22\n",
      "[15,    51] loss: 0.37533, train_accuracy: 87.70, time: 0.21\n",
      "[15,    61] loss: 0.39703, train_accuracy: 86.91, time: 0.22\n",
      "[15,    71] loss: 0.45627, train_accuracy: 84.96, time: 0.22\n",
      "[15,    81] loss: 0.43972, train_accuracy: 84.96, time: 0.21\n",
      "[15,    91] loss: 0.51942, train_accuracy: 82.81, time: 0.22\n",
      "duration: 21 s - train loss: 0.43815 - train accuracy: 84.78 - validation loss: 1.23 - validation accuracy: 68.60 \n",
      "[16,     1] loss: 0.38879, train_accuracy: 86.13, time: 0.22\n",
      "[16,    11] loss: 0.41601, train_accuracy: 86.52, time: 0.22\n",
      "[16,    21] loss: 0.43240, train_accuracy: 84.18, time: 0.22\n",
      "[16,    31] loss: 0.31767, train_accuracy: 87.89, time: 0.22\n",
      "[16,    41] loss: 0.34330, train_accuracy: 87.89, time: 0.22\n",
      "[16,    51] loss: 0.39644, train_accuracy: 86.13, time: 0.22\n",
      "[16,    61] loss: 0.44162, train_accuracy: 85.35, time: 0.21\n",
      "[16,    71] loss: 0.43315, train_accuracy: 86.33, time: 0.22\n",
      "[16,    81] loss: 0.39366, train_accuracy: 87.11, time: 0.22\n",
      "[16,    91] loss: 0.34312, train_accuracy: 89.06, time: 0.22\n",
      "duration: 21 s - train loss: 0.41127 - train accuracy: 85.77 - validation loss: 1.03 - validation accuracy: 73.42 \n",
      "[17,     1] loss: 0.41205, train_accuracy: 86.33, time: 0.22\n",
      "[17,    11] loss: 0.32801, train_accuracy: 88.48, time: 0.22\n",
      "[17,    21] loss: 0.35881, train_accuracy: 88.28, time: 0.22\n",
      "[17,    31] loss: 0.39323, train_accuracy: 85.35, time: 0.22\n",
      "[17,    41] loss: 0.37443, train_accuracy: 87.50, time: 0.22\n",
      "[17,    51] loss: 0.37676, train_accuracy: 85.16, time: 0.21\n",
      "[17,    61] loss: 0.39949, train_accuracy: 85.35, time: 0.21\n",
      "[17,    71] loss: 0.39669, train_accuracy: 85.16, time: 0.22\n",
      "[17,    81] loss: 0.37150, train_accuracy: 86.13, time: 0.22\n",
      "[17,    91] loss: 0.41643, train_accuracy: 84.96, time: 0.22\n",
      "duration: 21 s - train loss: 0.39001 - train accuracy: 86.53 - validation loss: 1.55 - validation accuracy: 62.72 \n",
      "[18,     1] loss: 0.36206, train_accuracy: 87.50, time: 0.22\n",
      "[18,    11] loss: 0.31856, train_accuracy: 87.50, time: 0.21\n",
      "[18,    21] loss: 0.40584, train_accuracy: 84.57, time: 0.22\n",
      "[18,    31] loss: 0.43609, train_accuracy: 85.55, time: 0.22\n",
      "[18,    41] loss: 0.34750, train_accuracy: 88.28, time: 0.22\n",
      "[18,    51] loss: 0.37064, train_accuracy: 86.52, time: 0.22\n",
      "[18,    61] loss: 0.40693, train_accuracy: 85.16, time: 0.22\n",
      "[18,    71] loss: 0.40049, train_accuracy: 87.50, time: 0.22\n",
      "[18,    81] loss: 0.40585, train_accuracy: 85.55, time: 0.21\n",
      "[18,    91] loss: 0.32914, train_accuracy: 88.09, time: 0.22\n",
      "duration: 21 s - train loss: 0.37216 - train accuracy: 87.17 - validation loss: 0.69 - validation accuracy: 78.41 \n",
      "[19,     1] loss: 0.32155, train_accuracy: 86.91, time: 0.21\n",
      "[19,    11] loss: 0.38460, train_accuracy: 86.33, time: 0.22\n",
      "[19,    21] loss: 0.32508, train_accuracy: 88.09, time: 0.22\n",
      "[19,    31] loss: 0.35048, train_accuracy: 84.96, time: 0.22\n",
      "[19,    41] loss: 0.33231, train_accuracy: 89.45, time: 0.22\n",
      "[19,    51] loss: 0.37175, train_accuracy: 88.28, time: 0.22\n",
      "[19,    61] loss: 0.35340, train_accuracy: 88.28, time: 0.22\n",
      "[19,    71] loss: 0.37327, train_accuracy: 85.94, time: 0.21\n",
      "[19,    81] loss: 0.32627, train_accuracy: 89.65, time: 0.22\n",
      "[19,    91] loss: 0.35262, train_accuracy: 86.13, time: 0.21\n",
      "duration: 21 s - train loss: 0.36160 - train accuracy: 87.50 - validation loss: 0.74 - validation accuracy: 77.81 \n",
      "[20,     1] loss: 0.32991, train_accuracy: 89.45, time: 0.22\n",
      "[20,    11] loss: 0.31705, train_accuracy: 88.67, time: 0.22\n",
      "[20,    21] loss: 0.33421, train_accuracy: 88.67, time: 0.21\n",
      "[20,    31] loss: 0.36315, train_accuracy: 87.30, time: 0.22\n",
      "[20,    41] loss: 0.29640, train_accuracy: 90.43, time: 0.22\n",
      "[20,    51] loss: 0.30287, train_accuracy: 91.02, time: 0.22\n",
      "[20,    61] loss: 0.33691, train_accuracy: 87.70, time: 0.22\n",
      "[20,    71] loss: 0.37225, train_accuracy: 88.28, time: 0.21\n",
      "[20,    81] loss: 0.31510, train_accuracy: 89.65, time: 0.22\n",
      "[20,    91] loss: 0.30487, train_accuracy: 90.04, time: 0.22\n",
      "duration: 21 s - train loss: 0.32838 - train accuracy: 88.68 - validation loss: 0.67 - validation accuracy: 80.50 \n",
      "[21,     1] loss: 0.31512, train_accuracy: 87.30, time: 0.22\n",
      "[21,    11] loss: 0.30373, train_accuracy: 89.45, time: 0.22\n",
      "[21,    21] loss: 0.34489, train_accuracy: 87.50, time: 0.22\n",
      "[21,    31] loss: 0.31604, train_accuracy: 89.26, time: 0.22\n",
      "[21,    41] loss: 0.34619, train_accuracy: 87.30, time: 0.22\n",
      "[21,    51] loss: 0.34892, train_accuracy: 87.50, time: 0.22\n",
      "[21,    61] loss: 0.22522, train_accuracy: 92.19, time: 0.22\n",
      "[21,    71] loss: 0.34586, train_accuracy: 88.28, time: 0.21\n",
      "[21,    81] loss: 0.34720, train_accuracy: 88.67, time: 0.22\n",
      "[21,    91] loss: 0.30383, train_accuracy: 89.45, time: 0.21\n",
      "duration: 21 s - train loss: 0.31727 - train accuracy: 89.00 - validation loss: 0.89 - validation accuracy: 75.57 \n",
      "[22,     1] loss: 0.34281, train_accuracy: 88.67, time: 0.21\n",
      "[22,    11] loss: 0.31210, train_accuracy: 90.04, time: 0.21\n",
      "[22,    21] loss: 0.25259, train_accuracy: 91.41, time: 0.22\n",
      "[22,    31] loss: 0.33607, train_accuracy: 88.09, time: 0.22\n",
      "[22,    41] loss: 0.29522, train_accuracy: 89.65, time: 0.22\n",
      "[22,    51] loss: 0.26890, train_accuracy: 90.43, time: 0.22\n",
      "[22,    61] loss: 0.35292, train_accuracy: 87.50, time: 0.22\n",
      "[22,    71] loss: 0.23858, train_accuracy: 91.21, time: 0.22\n",
      "[22,    81] loss: 0.28064, train_accuracy: 90.82, time: 0.21\n",
      "[22,    91] loss: 0.34136, train_accuracy: 89.26, time: 0.22\n",
      "duration: 21 s - train loss: 0.30277 - train accuracy: 89.52 - validation loss: 0.59 - validation accuracy: 82.09 \n",
      "[23,     1] loss: 0.28802, train_accuracy: 89.26, time: 0.22\n",
      "[23,    11] loss: 0.29102, train_accuracy: 89.26, time: 0.22\n",
      "[23,    21] loss: 0.25226, train_accuracy: 89.65, time: 0.22\n",
      "[23,    31] loss: 0.28489, train_accuracy: 90.04, time: 0.22\n",
      "[23,    41] loss: 0.27483, train_accuracy: 90.04, time: 0.22\n",
      "[23,    51] loss: 0.29796, train_accuracy: 89.65, time: 0.22\n",
      "[23,    61] loss: 0.23354, train_accuracy: 92.19, time: 0.22\n",
      "[23,    71] loss: 0.27920, train_accuracy: 89.84, time: 0.21\n",
      "[23,    81] loss: 0.25941, train_accuracy: 89.65, time: 0.21\n",
      "[23,    91] loss: 0.30036, train_accuracy: 88.87, time: 0.22\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "duration: 21 s - train loss: 0.28864 - train accuracy: 89.86 - validation loss: 0.74 - validation accuracy: 79.40 \n",
      "[24,     1] loss: 0.24826, train_accuracy: 91.60, time: 0.22\n",
      "[24,    11] loss: 0.24130, train_accuracy: 91.21, time: 0.21\n",
      "[24,    21] loss: 0.25133, train_accuracy: 91.02, time: 0.22\n",
      "[24,    31] loss: 0.24302, train_accuracy: 91.60, time: 0.21\n",
      "[24,    41] loss: 0.31349, train_accuracy: 89.26, time: 0.22\n",
      "[24,    51] loss: 0.32660, train_accuracy: 87.50, time: 0.21\n",
      "[24,    61] loss: 0.24841, train_accuracy: 91.80, time: 0.22\n",
      "[24,    71] loss: 0.25528, train_accuracy: 92.38, time: 0.22\n",
      "[24,    81] loss: 0.28798, train_accuracy: 91.02, time: 0.22\n",
      "[24,    91] loss: 0.32571, train_accuracy: 88.28, time: 0.22\n",
      "duration: 21 s - train loss: 0.28075 - train accuracy: 90.36 - validation loss: 1.12 - validation accuracy: 72.42 \n",
      "[25,     1] loss: 0.19596, train_accuracy: 92.77, time: 0.22\n",
      "[25,    11] loss: 0.19380, train_accuracy: 93.95, time: 0.21\n",
      "[25,    21] loss: 0.24630, train_accuracy: 92.38, time: 0.21\n",
      "[25,    31] loss: 0.27756, train_accuracy: 89.84, time: 0.22\n",
      "[25,    41] loss: 0.28347, train_accuracy: 91.02, time: 0.22\n",
      "[25,    51] loss: 0.28422, train_accuracy: 90.62, time: 0.22\n",
      "[25,    61] loss: 0.26158, train_accuracy: 89.65, time: 0.21\n",
      "[25,    71] loss: 0.28762, train_accuracy: 91.02, time: 0.22\n",
      "[25,    81] loss: 0.29173, train_accuracy: 89.45, time: 0.21\n",
      "[25,    91] loss: 0.28923, train_accuracy: 88.67, time: 0.22\n",
      "duration: 21 s - train loss: 0.26699 - train accuracy: 90.72 - validation loss: 0.67 - validation accuracy: 80.65 \n",
      "[26,     1] loss: 0.24747, train_accuracy: 92.19, time: 0.22\n",
      "[26,    11] loss: 0.36451, train_accuracy: 86.33, time: 0.21\n",
      "[26,    21] loss: 0.17724, train_accuracy: 92.77, time: 0.22\n",
      "[26,    31] loss: 0.26446, train_accuracy: 90.04, time: 0.22\n",
      "[26,    41] loss: 0.24837, train_accuracy: 90.62, time: 0.21\n",
      "[26,    51] loss: 0.28152, train_accuracy: 90.23, time: 0.22\n",
      "[26,    61] loss: 0.22265, train_accuracy: 91.80, time: 0.21\n",
      "[26,    71] loss: 0.25237, train_accuracy: 89.06, time: 0.22\n",
      "[26,    81] loss: 0.29132, train_accuracy: 88.48, time: 0.22\n",
      "[26,    91] loss: 0.24023, train_accuracy: 90.43, time: 0.22\n",
      "duration: 21 s - train loss: 0.25396 - train accuracy: 91.03 - validation loss: 0.95 - validation accuracy: 77.61 \n",
      "[27,     1] loss: 0.23760, train_accuracy: 91.60, time: 0.21\n",
      "[27,    11] loss: 0.23243, train_accuracy: 91.99, time: 0.22\n",
      "[27,    21] loss: 0.23937, train_accuracy: 91.60, time: 0.22\n",
      "[27,    31] loss: 0.27319, train_accuracy: 91.21, time: 0.22\n",
      "[27,    41] loss: 0.27558, train_accuracy: 90.23, time: 0.22\n",
      "[27,    51] loss: 0.24647, train_accuracy: 91.80, time: 0.22\n",
      "[27,    61] loss: 0.22413, train_accuracy: 92.38, time: 0.21\n",
      "[27,    71] loss: 0.23669, train_accuracy: 92.38, time: 0.21\n",
      "[27,    81] loss: 0.29525, train_accuracy: 91.41, time: 0.22\n",
      "[27,    91] loss: 0.21902, train_accuracy: 92.38, time: 0.22\n",
      "duration: 21 s - train loss: 0.24325 - train accuracy: 91.40 - validation loss: 0.85 - validation accuracy: 78.38 \n",
      "[28,     1] loss: 0.17806, train_accuracy: 93.36, time: 0.21\n",
      "[28,    11] loss: 0.21672, train_accuracy: 92.77, time: 0.22\n",
      "[28,    21] loss: 0.22416, train_accuracy: 91.60, time: 0.21\n",
      "[28,    31] loss: 0.22822, train_accuracy: 91.02, time: 0.22\n",
      "[28,    41] loss: 0.23491, train_accuracy: 91.80, time: 0.22\n",
      "[28,    51] loss: 0.27040, train_accuracy: 90.82, time: 0.22\n",
      "[28,    61] loss: 0.27872, train_accuracy: 90.62, time: 0.22\n",
      "[28,    71] loss: 0.24522, train_accuracy: 91.41, time: 0.22\n",
      "[28,    81] loss: 0.21578, train_accuracy: 92.77, time: 0.22\n",
      "[28,    91] loss: 0.15383, train_accuracy: 93.75, time: 0.22\n",
      "duration: 21 s - train loss: 0.23703 - train accuracy: 91.75 - validation loss: 0.65 - validation accuracy: 80.43 \n",
      "[29,     1] loss: 0.23071, train_accuracy: 90.82, time: 0.22\n",
      "[29,    11] loss: 0.21397, train_accuracy: 93.36, time: 0.21\n",
      "[29,    21] loss: 0.22430, train_accuracy: 91.41, time: 0.22\n",
      "[29,    31] loss: 0.23569, train_accuracy: 93.16, time: 0.22\n",
      "[29,    41] loss: 0.19132, train_accuracy: 93.36, time: 0.21\n",
      "[29,    51] loss: 0.23709, train_accuracy: 91.41, time: 0.21\n",
      "[29,    61] loss: 0.29691, train_accuracy: 89.45, time: 0.22\n",
      "[29,    71] loss: 0.22858, train_accuracy: 91.41, time: 0.22\n",
      "[29,    81] loss: 0.20315, train_accuracy: 92.58, time: 0.21\n",
      "[29,    91] loss: 0.25540, train_accuracy: 91.80, time: 0.21\n",
      "duration: 21 s - train loss: 0.23156 - train accuracy: 91.82 - validation loss: 0.82 - validation accuracy: 79.98 \n",
      "[30,     1] loss: 0.23126, train_accuracy: 91.80, time: 0.21\n",
      "[30,    11] loss: 0.20099, train_accuracy: 93.55, time: 0.22\n",
      "[30,    21] loss: 0.22588, train_accuracy: 92.19, time: 0.22\n",
      "[30,    31] loss: 0.22101, train_accuracy: 92.77, time: 0.21\n",
      "[30,    41] loss: 0.21324, train_accuracy: 93.36, time: 0.22\n",
      "[30,    51] loss: 0.20009, train_accuracy: 93.36, time: 0.21\n",
      "[30,    61] loss: 0.17911, train_accuracy: 92.77, time: 0.22\n",
      "[30,    71] loss: 0.19250, train_accuracy: 91.99, time: 0.22\n",
      "[30,    81] loss: 0.21465, train_accuracy: 92.38, time: 0.22\n",
      "[30,    91] loss: 0.20382, train_accuracy: 92.58, time: 0.22\n",
      "duration: 21 s - train loss: 0.21766 - train accuracy: 92.31 - validation loss: 0.79 - validation accuracy: 80.20 \n",
      "[31,     1] loss: 0.22009, train_accuracy: 92.19, time: 0.22\n",
      "[31,    11] loss: 0.20155, train_accuracy: 93.16, time: 0.22\n",
      "[31,    21] loss: 0.24394, train_accuracy: 92.19, time: 0.22\n",
      "[31,    31] loss: 0.27926, train_accuracy: 89.84, time: 0.22\n",
      "[31,    41] loss: 0.23134, train_accuracy: 91.21, time: 0.22\n",
      "[31,    51] loss: 0.20024, train_accuracy: 92.77, time: 0.22\n",
      "[31,    61] loss: 0.23696, train_accuracy: 90.23, time: 0.22\n",
      "[31,    71] loss: 0.22094, train_accuracy: 91.99, time: 0.21\n",
      "[31,    81] loss: 0.24527, train_accuracy: 90.82, time: 0.22\n",
      "[31,    91] loss: 0.21375, train_accuracy: 92.58, time: 0.21\n",
      "duration: 21 s - train loss: 0.21365 - train accuracy: 92.64 - validation loss: 0.70 - validation accuracy: 81.39 \n",
      "[32,     1] loss: 0.20671, train_accuracy: 91.80, time: 0.22\n",
      "[32,    11] loss: 0.17485, train_accuracy: 94.34, time: 0.22\n",
      "[32,    21] loss: 0.22690, train_accuracy: 93.16, time: 0.22\n",
      "[32,    31] loss: 0.21396, train_accuracy: 92.38, time: 0.21\n",
      "[32,    41] loss: 0.19924, train_accuracy: 93.36, time: 0.22\n",
      "[32,    51] loss: 0.20176, train_accuracy: 93.95, time: 0.22\n",
      "[32,    61] loss: 0.18114, train_accuracy: 92.58, time: 0.21\n",
      "[32,    71] loss: 0.25703, train_accuracy: 90.04, time: 0.22\n",
      "[32,    81] loss: 0.27264, train_accuracy: 91.99, time: 0.22\n",
      "[32,    91] loss: 0.19413, train_accuracy: 92.97, time: 0.22\n",
      "duration: 21 s - train loss: 0.21057 - train accuracy: 92.72 - validation loss: 0.75 - validation accuracy: 79.04 \n",
      "[33,     1] loss: 0.18063, train_accuracy: 94.34, time: 0.22\n",
      "[33,    11] loss: 0.16070, train_accuracy: 94.34, time: 0.22\n",
      "[33,    21] loss: 0.17178, train_accuracy: 92.38, time: 0.22\n",
      "[33,    31] loss: 0.17070, train_accuracy: 92.77, time: 0.22\n",
      "[33,    41] loss: 0.15246, train_accuracy: 94.53, time: 0.21\n",
      "[33,    51] loss: 0.17620, train_accuracy: 93.36, time: 0.22\n",
      "[33,    61] loss: 0.16727, train_accuracy: 95.90, time: 0.22\n",
      "[33,    71] loss: 0.22126, train_accuracy: 92.58, time: 0.22\n",
      "[33,    81] loss: 0.19874, train_accuracy: 93.36, time: 0.22\n",
      "[33,    91] loss: 0.20730, train_accuracy: 92.77, time: 0.21\n",
      "duration: 21 s - train loss: 0.19456 - train accuracy: 93.13 - validation loss: 0.62 - validation accuracy: 82.69 \n",
      "[34,     1] loss: 0.16643, train_accuracy: 94.92, time: 0.22\n",
      "[34,    11] loss: 0.17085, train_accuracy: 93.95, time: 0.21\n",
      "[34,    21] loss: 0.20314, train_accuracy: 92.58, time: 0.22\n",
      "[34,    31] loss: 0.16515, train_accuracy: 94.34, time: 0.22\n",
      "[34,    41] loss: 0.16193, train_accuracy: 94.34, time: 0.22\n",
      "[34,    51] loss: 0.14464, train_accuracy: 95.31, time: 0.21\n",
      "[34,    61] loss: 0.19349, train_accuracy: 92.38, time: 0.22\n",
      "[34,    71] loss: 0.19292, train_accuracy: 93.75, time: 0.22\n",
      "[34,    81] loss: 0.13784, train_accuracy: 94.73, time: 0.21\n",
      "[34,    91] loss: 0.18371, train_accuracy: 94.92, time: 0.22\n",
      "duration: 21 s - train loss: 0.18519 - train accuracy: 93.55 - validation loss: 0.75 - validation accuracy: 82.15 \n",
      "[35,     1] loss: 0.17575, train_accuracy: 92.97, time: 0.22\n",
      "[35,    11] loss: 0.21925, train_accuracy: 91.41, time: 0.21\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[35,    21] loss: 0.18538, train_accuracy: 94.14, time: 0.22\n",
      "[35,    31] loss: 0.15778, train_accuracy: 94.34, time: 0.21\n",
      "[35,    41] loss: 0.17411, train_accuracy: 92.97, time: 0.21\n",
      "[35,    51] loss: 0.27937, train_accuracy: 90.82, time: 0.21\n",
      "[35,    61] loss: 0.16613, train_accuracy: 93.36, time: 0.22\n",
      "[35,    71] loss: 0.23233, train_accuracy: 90.62, time: 0.22\n",
      "[35,    81] loss: 0.20276, train_accuracy: 93.95, time: 0.22\n",
      "[35,    91] loss: 0.17553, train_accuracy: 93.55, time: 0.21\n",
      "duration: 21 s - train loss: 0.19217 - train accuracy: 93.26 - validation loss: 0.82 - validation accuracy: 81.72 \n",
      "[36,     1] loss: 0.11530, train_accuracy: 96.88, time: 0.22\n",
      "[36,    11] loss: 0.17840, train_accuracy: 93.16, time: 0.21\n",
      "[36,    21] loss: 0.16246, train_accuracy: 94.92, time: 0.22\n",
      "[36,    31] loss: 0.18018, train_accuracy: 92.97, time: 0.22\n",
      "[36,    41] loss: 0.18178, train_accuracy: 93.55, time: 0.22\n",
      "[36,    51] loss: 0.24731, train_accuracy: 92.38, time: 0.22\n",
      "[36,    61] loss: 0.14275, train_accuracy: 94.53, time: 0.22\n",
      "[36,    71] loss: 0.16535, train_accuracy: 94.73, time: 0.21\n",
      "[36,    81] loss: 0.21575, train_accuracy: 92.58, time: 0.21\n",
      "[36,    91] loss: 0.24600, train_accuracy: 91.21, time: 0.21\n",
      "duration: 21 s - train loss: 0.18337 - train accuracy: 93.64 - validation loss: 0.78 - validation accuracy: 80.92 \n",
      "[37,     1] loss: 0.16954, train_accuracy: 94.14, time: 0.21\n",
      "[37,    11] loss: 0.22732, train_accuracy: 91.99, time: 0.22\n",
      "[37,    21] loss: 0.14446, train_accuracy: 95.31, time: 0.22\n",
      "[37,    31] loss: 0.17329, train_accuracy: 94.53, time: 0.22\n",
      "[37,    41] loss: 0.17507, train_accuracy: 92.97, time: 0.22\n",
      "[37,    51] loss: 0.19027, train_accuracy: 92.77, time: 0.22\n",
      "[37,    61] loss: 0.12563, train_accuracy: 95.31, time: 0.21\n",
      "[37,    71] loss: 0.10356, train_accuracy: 96.48, time: 0.22\n",
      "[37,    81] loss: 0.17362, train_accuracy: 95.31, time: 0.22\n",
      "[37,    91] loss: 0.15080, train_accuracy: 94.73, time: 0.22\n",
      "duration: 21 s - train loss: 0.17103 - train accuracy: 94.08 - validation loss: 0.66 - validation accuracy: 84.44 \n",
      "[38,     1] loss: 0.16115, train_accuracy: 94.73, time: 0.22\n",
      "[38,    11] loss: 0.14080, train_accuracy: 93.75, time: 0.22\n",
      "[38,    21] loss: 0.17457, train_accuracy: 93.95, time: 0.22\n",
      "[38,    31] loss: 0.15787, train_accuracy: 94.34, time: 0.22\n",
      "[38,    41] loss: 0.12485, train_accuracy: 96.09, time: 0.22\n",
      "[38,    51] loss: 0.18437, train_accuracy: 93.36, time: 0.22\n",
      "[38,    61] loss: 0.14814, train_accuracy: 95.51, time: 0.22\n",
      "[38,    71] loss: 0.13701, train_accuracy: 95.31, time: 0.22\n",
      "[38,    81] loss: 0.22040, train_accuracy: 91.80, time: 0.21\n",
      "[38,    91] loss: 0.18316, train_accuracy: 93.75, time: 0.21\n",
      "duration: 21 s - train loss: 0.16233 - train accuracy: 94.20 - validation loss: 0.80 - validation accuracy: 82.46 \n",
      "[39,     1] loss: 0.12379, train_accuracy: 94.92, time: 0.22\n",
      "[39,    11] loss: 0.16026, train_accuracy: 94.92, time: 0.22\n",
      "[39,    21] loss: 0.12616, train_accuracy: 95.51, time: 0.21\n",
      "[39,    31] loss: 0.15361, train_accuracy: 93.55, time: 0.22\n",
      "[39,    41] loss: 0.19326, train_accuracy: 94.34, time: 0.22\n",
      "[39,    51] loss: 0.17202, train_accuracy: 95.12, time: 0.22\n",
      "[39,    61] loss: 0.12052, train_accuracy: 96.48, time: 0.22\n",
      "[39,    71] loss: 0.21066, train_accuracy: 93.95, time: 0.22\n",
      "[39,    81] loss: 0.17664, train_accuracy: 92.97, time: 0.22\n",
      "[39,    91] loss: 0.14546, train_accuracy: 95.70, time: 0.21\n",
      "duration: 21 s - train loss: 0.16299 - train accuracy: 94.32 - validation loss: 0.61 - validation accuracy: 84.55 \n",
      "[40,     1] loss: 0.16569, train_accuracy: 94.34, time: 0.21\n",
      "[40,    11] loss: 0.13575, train_accuracy: 95.70, time: 0.21\n",
      "[40,    21] loss: 0.14057, train_accuracy: 95.12, time: 0.21\n",
      "[40,    31] loss: 0.17605, train_accuracy: 94.34, time: 0.22\n",
      "[40,    41] loss: 0.17324, train_accuracy: 94.14, time: 0.22\n",
      "[40,    51] loss: 0.10153, train_accuracy: 96.29, time: 0.21\n",
      "[40,    61] loss: 0.16067, train_accuracy: 94.34, time: 0.22\n",
      "[40,    71] loss: 0.13678, train_accuracy: 95.31, time: 0.21\n",
      "[40,    81] loss: 0.23713, train_accuracy: 90.62, time: 0.22\n",
      "[40,    91] loss: 0.15879, train_accuracy: 95.51, time: 0.21\n",
      "duration: 21 s - train loss: 0.15281 - train accuracy: 94.64 - validation loss: 0.75 - validation accuracy: 82.99 \n",
      "[41,     1] loss: 0.10767, train_accuracy: 96.88, time: 0.22\n",
      "[41,    11] loss: 0.13795, train_accuracy: 94.92, time: 0.22\n",
      "[41,    21] loss: 0.12398, train_accuracy: 95.12, time: 0.21\n",
      "[41,    31] loss: 0.12584, train_accuracy: 95.70, time: 0.22\n",
      "[41,    41] loss: 0.13757, train_accuracy: 95.31, time: 0.21\n",
      "[41,    51] loss: 0.14446, train_accuracy: 94.53, time: 0.21\n",
      "[41,    61] loss: 0.17798, train_accuracy: 94.53, time: 0.22\n",
      "[41,    71] loss: 0.15960, train_accuracy: 94.14, time: 0.21\n",
      "[41,    81] loss: 0.14733, train_accuracy: 95.51, time: 0.22\n",
      "[41,    91] loss: 0.19962, train_accuracy: 94.34, time: 0.21\n",
      "duration: 21 s - train loss: 0.15361 - train accuracy: 94.66 - validation loss: 0.70 - validation accuracy: 82.78 \n",
      "[42,     1] loss: 0.12839, train_accuracy: 95.90, time: 0.21\n",
      "[42,    11] loss: 0.14309, train_accuracy: 94.73, time: 0.22\n",
      "[42,    21] loss: 0.12022, train_accuracy: 95.12, time: 0.21\n",
      "[42,    31] loss: 0.13307, train_accuracy: 95.12, time: 0.22\n",
      "[42,    41] loss: 0.08231, train_accuracy: 97.27, time: 0.21\n",
      "[42,    51] loss: 0.18839, train_accuracy: 93.75, time: 0.22\n",
      "[42,    61] loss: 0.16314, train_accuracy: 94.53, time: 0.21\n",
      "[42,    71] loss: 0.15583, train_accuracy: 94.34, time: 0.22\n",
      "[42,    81] loss: 0.21603, train_accuracy: 92.97, time: 0.22\n",
      "[42,    91] loss: 0.14652, train_accuracy: 95.12, time: 0.21\n",
      "duration: 21 s - train loss: 0.14875 - train accuracy: 94.66 - validation loss: 0.79 - validation accuracy: 82.72 \n",
      "[43,     1] loss: 0.14530, train_accuracy: 94.53, time: 0.22\n",
      "[43,    11] loss: 0.12753, train_accuracy: 95.90, time: 0.22\n",
      "[43,    21] loss: 0.13667, train_accuracy: 95.31, time: 0.21\n",
      "[43,    31] loss: 0.16574, train_accuracy: 94.14, time: 0.21\n",
      "[43,    41] loss: 0.16379, train_accuracy: 94.14, time: 0.22\n",
      "[43,    51] loss: 0.10846, train_accuracy: 96.29, time: 0.22\n",
      "[43,    61] loss: 0.15098, train_accuracy: 94.53, time: 0.21\n",
      "[43,    71] loss: 0.18456, train_accuracy: 93.55, time: 0.22\n",
      "[43,    81] loss: 0.12861, train_accuracy: 95.31, time: 0.22\n",
      "[43,    91] loss: 0.10697, train_accuracy: 96.48, time: 0.22\n",
      "duration: 21 s - train loss: 0.13951 - train accuracy: 95.13 - validation loss: 0.78 - validation accuracy: 83.72 \n",
      "[44,     1] loss: 0.09245, train_accuracy: 96.68, time: 0.22\n",
      "[44,    11] loss: 0.13250, train_accuracy: 95.31, time: 0.22\n",
      "[44,    21] loss: 0.15521, train_accuracy: 94.14, time: 0.22\n",
      "[44,    31] loss: 0.19097, train_accuracy: 93.95, time: 0.22\n",
      "[44,    41] loss: 0.10511, train_accuracy: 96.29, time: 0.22\n",
      "[44,    51] loss: 0.10207, train_accuracy: 95.90, time: 0.22\n",
      "[44,    61] loss: 0.11114, train_accuracy: 96.29, time: 0.22\n",
      "[44,    71] loss: 0.16007, train_accuracy: 94.14, time: 0.22\n",
      "[44,    81] loss: 0.11786, train_accuracy: 96.09, time: 0.22\n",
      "[44,    91] loss: 0.13086, train_accuracy: 95.51, time: 0.22\n",
      "duration: 21 s - train loss: 0.13537 - train accuracy: 95.34 - validation loss: 0.62 - validation accuracy: 84.94 \n",
      "[45,     1] loss: 0.09400, train_accuracy: 96.88, time: 0.22\n",
      "[45,    11] loss: 0.11739, train_accuracy: 96.09, time: 0.21\n",
      "[45,    21] loss: 0.12976, train_accuracy: 96.48, time: 0.21\n",
      "[45,    31] loss: 0.15441, train_accuracy: 93.36, time: 0.22\n",
      "[45,    41] loss: 0.14569, train_accuracy: 95.31, time: 0.21\n",
      "[45,    51] loss: 0.14776, train_accuracy: 93.95, time: 0.22\n",
      "[45,    61] loss: 0.12910, train_accuracy: 95.70, time: 0.22\n",
      "[45,    71] loss: 0.07317, train_accuracy: 96.68, time: 0.21\n",
      "[45,    81] loss: 0.15039, train_accuracy: 94.92, time: 0.22\n",
      "[45,    91] loss: 0.12548, train_accuracy: 95.12, time: 0.22\n",
      "duration: 21 s - train loss: 0.13207 - train accuracy: 95.38 - validation loss: 0.64 - validation accuracy: 84.47 \n",
      "[46,     1] loss: 0.08620, train_accuracy: 97.27, time: 0.22\n",
      "[46,    11] loss: 0.11307, train_accuracy: 96.29, time: 0.21\n",
      "[46,    21] loss: 0.11838, train_accuracy: 96.48, time: 0.22\n",
      "[46,    31] loss: 0.12922, train_accuracy: 94.92, time: 0.22\n",
      "[46,    41] loss: 0.17517, train_accuracy: 93.55, time: 0.21\n",
      "[46,    51] loss: 0.11563, train_accuracy: 95.90, time: 0.22\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[46,    61] loss: 0.10638, train_accuracy: 96.09, time: 0.22\n",
      "[46,    71] loss: 0.13524, train_accuracy: 94.73, time: 0.22\n",
      "[46,    81] loss: 0.11968, train_accuracy: 96.09, time: 0.21\n",
      "[46,    91] loss: 0.12787, train_accuracy: 95.90, time: 0.21\n",
      "duration: 21 s - train loss: 0.12761 - train accuracy: 95.54 - validation loss: 0.64 - validation accuracy: 85.05 \n",
      "[47,     1] loss: 0.09298, train_accuracy: 96.48, time: 0.22\n",
      "[47,    11] loss: 0.14290, train_accuracy: 95.31, time: 0.22\n",
      "[47,    21] loss: 0.10729, train_accuracy: 96.48, time: 0.22\n",
      "[47,    31] loss: 0.11930, train_accuracy: 97.27, time: 0.21\n",
      "[47,    41] loss: 0.11706, train_accuracy: 95.12, time: 0.22\n",
      "[47,    51] loss: 0.11583, train_accuracy: 96.88, time: 0.22\n",
      "[47,    61] loss: 0.10102, train_accuracy: 96.68, time: 0.22\n",
      "[47,    71] loss: 0.15364, train_accuracy: 94.53, time: 0.22\n",
      "[47,    81] loss: 0.12495, train_accuracy: 95.51, time: 0.21\n",
      "[47,    91] loss: 0.12622, train_accuracy: 96.09, time: 0.21\n",
      "duration: 21 s - train loss: 0.12689 - train accuracy: 95.58 - validation loss: 0.82 - validation accuracy: 82.31 \n",
      "[48,     1] loss: 0.15799, train_accuracy: 95.31, time: 0.22\n",
      "[48,    11] loss: 0.11700, train_accuracy: 96.48, time: 0.21\n",
      "[48,    21] loss: 0.12278, train_accuracy: 95.70, time: 0.22\n",
      "[48,    31] loss: 0.12323, train_accuracy: 95.70, time: 0.21\n",
      "[48,    41] loss: 0.09831, train_accuracy: 95.90, time: 0.22\n",
      "[48,    51] loss: 0.06600, train_accuracy: 97.85, time: 0.21\n",
      "[48,    61] loss: 0.14442, train_accuracy: 94.53, time: 0.22\n",
      "[48,    71] loss: 0.11025, train_accuracy: 96.48, time: 0.22\n",
      "[48,    81] loss: 0.14992, train_accuracy: 93.75, time: 0.22\n",
      "[48,    91] loss: 0.11736, train_accuracy: 95.51, time: 0.22\n",
      "duration: 21 s - train loss: 0.11793 - train accuracy: 95.89 - validation loss: 0.76 - validation accuracy: 84.10 \n",
      "[49,     1] loss: 0.07344, train_accuracy: 97.46, time: 0.21\n",
      "[49,    11] loss: 0.10645, train_accuracy: 96.88, time: 0.22\n",
      "[49,    21] loss: 0.13237, train_accuracy: 95.90, time: 0.22\n",
      "[49,    31] loss: 0.10557, train_accuracy: 96.68, time: 0.21\n",
      "[49,    41] loss: 0.10468, train_accuracy: 96.48, time: 0.21\n",
      "[49,    51] loss: 0.12085, train_accuracy: 96.48, time: 0.21\n",
      "[49,    61] loss: 0.07395, train_accuracy: 97.85, time: 0.22\n",
      "[49,    71] loss: 0.14197, train_accuracy: 94.92, time: 0.21\n",
      "[49,    81] loss: 0.14766, train_accuracy: 94.53, time: 0.21\n",
      "[49,    91] loss: 0.11688, train_accuracy: 94.92, time: 0.21\n",
      "duration: 21 s - train loss: 0.11920 - train accuracy: 95.80 - validation loss: 0.70 - validation accuracy: 84.02 \n",
      "[50,     1] loss: 0.11471, train_accuracy: 95.70, time: 0.21\n",
      "[50,    11] loss: 0.09999, train_accuracy: 95.51, time: 0.21\n",
      "[50,    21] loss: 0.10770, train_accuracy: 96.68, time: 0.21\n",
      "[50,    31] loss: 0.08890, train_accuracy: 96.68, time: 0.21\n",
      "[50,    41] loss: 0.10324, train_accuracy: 96.29, time: 0.22\n",
      "[50,    51] loss: 0.09992, train_accuracy: 95.70, time: 0.21\n",
      "[50,    61] loss: 0.09518, train_accuracy: 96.88, time: 0.21\n",
      "[50,    71] loss: 0.09447, train_accuracy: 96.09, time: 0.21\n",
      "[50,    81] loss: 0.12667, train_accuracy: 94.92, time: 0.22\n",
      "[50,    91] loss: 0.11584, train_accuracy: 96.88, time: 0.22\n",
      "duration: 21 s - train loss: 0.11904 - train accuracy: 95.81 - validation loss: 0.66 - validation accuracy: 85.29 \n",
      "[51,     1] loss: 0.12307, train_accuracy: 95.51, time: 0.22\n",
      "[51,    11] loss: 0.10573, train_accuracy: 95.51, time: 0.22\n",
      "[51,    21] loss: 0.13729, train_accuracy: 95.90, time: 0.21\n",
      "[51,    31] loss: 0.11590, train_accuracy: 95.70, time: 0.22\n",
      "[51,    41] loss: 0.11458, train_accuracy: 95.70, time: 0.21\n",
      "[51,    51] loss: 0.09300, train_accuracy: 96.48, time: 0.21\n",
      "[51,    61] loss: 0.08724, train_accuracy: 97.27, time: 0.21\n",
      "[51,    71] loss: 0.17183, train_accuracy: 94.14, time: 0.21\n",
      "[51,    81] loss: 0.09361, train_accuracy: 96.68, time: 0.22\n",
      "[51,    91] loss: 0.13557, train_accuracy: 95.12, time: 0.22\n",
      "duration: 21 s - train loss: 0.12030 - train accuracy: 95.84 - validation loss: 0.62 - validation accuracy: 85.19 \n",
      "[52,     1] loss: 0.08747, train_accuracy: 96.88, time: 0.22\n",
      "[52,    11] loss: 0.07976, train_accuracy: 96.68, time: 0.22\n",
      "[52,    21] loss: 0.11882, train_accuracy: 96.68, time: 0.22\n",
      "[52,    31] loss: 0.09538, train_accuracy: 95.90, time: 0.22\n",
      "[52,    41] loss: 0.06263, train_accuracy: 98.44, time: 0.21\n",
      "[52,    51] loss: 0.13032, train_accuracy: 95.31, time: 0.22\n",
      "[52,    61] loss: 0.10274, train_accuracy: 97.07, time: 0.22\n",
      "[52,    71] loss: 0.12833, train_accuracy: 95.12, time: 0.22\n",
      "[52,    81] loss: 0.08045, train_accuracy: 97.46, time: 0.21\n",
      "[52,    91] loss: 0.10772, train_accuracy: 96.09, time: 0.22\n",
      "duration: 21 s - train loss: 0.11322 - train accuracy: 96.00 - validation loss: 0.89 - validation accuracy: 81.70 \n",
      "[53,     1] loss: 0.11895, train_accuracy: 95.31, time: 0.21\n",
      "[53,    11] loss: 0.09574, train_accuracy: 96.68, time: 0.21\n",
      "[53,    21] loss: 0.11196, train_accuracy: 96.29, time: 0.22\n",
      "[53,    31] loss: 0.10732, train_accuracy: 96.09, time: 0.22\n",
      "[53,    41] loss: 0.10709, train_accuracy: 96.09, time: 0.22\n",
      "[53,    51] loss: 0.16332, train_accuracy: 94.53, time: 0.22\n",
      "[53,    61] loss: 0.09961, train_accuracy: 95.90, time: 0.22\n",
      "[53,    71] loss: 0.13372, train_accuracy: 95.12, time: 0.22\n",
      "[53,    81] loss: 0.10312, train_accuracy: 96.09, time: 0.22\n",
      "[53,    91] loss: 0.09274, train_accuracy: 96.29, time: 0.21\n",
      "duration: 21 s - train loss: 0.10724 - train accuracy: 96.24 - validation loss: 0.86 - validation accuracy: 82.54 \n",
      "[54,     1] loss: 0.12426, train_accuracy: 96.29, time: 0.22\n",
      "[54,    11] loss: 0.09134, train_accuracy: 95.70, time: 0.22\n",
      "[54,    21] loss: 0.11712, train_accuracy: 96.88, time: 0.22\n",
      "[54,    31] loss: 0.10073, train_accuracy: 96.48, time: 0.22\n",
      "[54,    41] loss: 0.11913, train_accuracy: 96.09, time: 0.22\n",
      "[54,    51] loss: 0.10987, train_accuracy: 96.09, time: 0.22\n",
      "[54,    61] loss: 0.12983, train_accuracy: 95.51, time: 0.22\n",
      "[54,    71] loss: 0.13864, train_accuracy: 94.73, time: 0.22\n",
      "[54,    81] loss: 0.11890, train_accuracy: 96.29, time: 0.22\n",
      "[54,    91] loss: 0.11911, train_accuracy: 95.90, time: 0.22\n",
      "duration: 21 s - train loss: 0.10605 - train accuracy: 96.28 - validation loss: 0.76 - validation accuracy: 84.40 \n",
      "[55,     1] loss: 0.12497, train_accuracy: 95.51, time: 0.22\n",
      "[55,    11] loss: 0.08043, train_accuracy: 96.68, time: 0.22\n",
      "[55,    21] loss: 0.09443, train_accuracy: 96.29, time: 0.22\n",
      "[55,    31] loss: 0.08191, train_accuracy: 96.48, time: 0.22\n",
      "[55,    41] loss: 0.12252, train_accuracy: 95.51, time: 0.22\n",
      "[55,    51] loss: 0.10134, train_accuracy: 97.07, time: 0.22\n",
      "[55,    61] loss: 0.10223, train_accuracy: 96.29, time: 0.21\n",
      "[55,    71] loss: 0.09074, train_accuracy: 96.88, time: 0.22\n",
      "[55,    81] loss: 0.10192, train_accuracy: 96.68, time: 0.21\n",
      "[55,    91] loss: 0.07173, train_accuracy: 97.27, time: 0.21\n",
      "duration: 21 s - train loss: 0.09895 - train accuracy: 96.49 - validation loss: 1.06 - validation accuracy: 80.82 \n",
      "[56,     1] loss: 0.11598, train_accuracy: 95.70, time: 0.22\n",
      "[56,    11] loss: 0.06882, train_accuracy: 96.48, time: 0.22\n",
      "[56,    21] loss: 0.08771, train_accuracy: 96.29, time: 0.21\n",
      "[56,    31] loss: 0.09861, train_accuracy: 95.51, time: 0.22\n",
      "[56,    41] loss: 0.06777, train_accuracy: 97.85, time: 0.22\n",
      "[56,    51] loss: 0.08217, train_accuracy: 96.68, time: 0.22\n",
      "[56,    61] loss: 0.08434, train_accuracy: 96.88, time: 0.21\n",
      "[56,    71] loss: 0.11002, train_accuracy: 96.68, time: 0.22\n",
      "[56,    81] loss: 0.11661, train_accuracy: 96.48, time: 0.21\n",
      "[56,    91] loss: 0.09547, train_accuracy: 95.90, time: 0.21\n",
      "duration: 21 s - train loss: 0.09523 - train accuracy: 96.68 - validation loss: 0.98 - validation accuracy: 80.73 \n",
      "[57,     1] loss: 0.06656, train_accuracy: 96.68, time: 0.22\n",
      "[57,    11] loss: 0.08533, train_accuracy: 96.88, time: 0.21\n",
      "[57,    21] loss: 0.06994, train_accuracy: 97.27, time: 0.21\n",
      "[57,    31] loss: 0.10866, train_accuracy: 96.48, time: 0.22\n",
      "[57,    41] loss: 0.11381, train_accuracy: 95.51, time: 0.21\n",
      "[57,    51] loss: 0.08298, train_accuracy: 96.88, time: 0.22\n",
      "[57,    61] loss: 0.12378, train_accuracy: 95.70, time: 0.22\n",
      "[57,    71] loss: 0.08631, train_accuracy: 97.27, time: 0.22\n",
      "[57,    81] loss: 0.06074, train_accuracy: 98.05, time: 0.22\n",
      "[57,    91] loss: 0.10657, train_accuracy: 96.29, time: 0.22\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "duration: 21 s - train loss: 0.09974 - train accuracy: 96.49 - validation loss: 1.88 - validation accuracy: 70.07 \n",
      "[58,     1] loss: 0.09201, train_accuracy: 95.90, time: 0.22\n",
      "[58,    11] loss: 0.08211, train_accuracy: 97.27, time: 0.21\n",
      "[58,    21] loss: 0.13349, train_accuracy: 96.29, time: 0.22\n",
      "[58,    31] loss: 0.11773, train_accuracy: 95.51, time: 0.21\n",
      "[58,    41] loss: 0.10411, train_accuracy: 96.68, time: 0.21\n",
      "[58,    51] loss: 0.07550, train_accuracy: 97.27, time: 0.22\n",
      "[58,    61] loss: 0.08089, train_accuracy: 96.88, time: 0.22\n",
      "[58,    71] loss: 0.07216, train_accuracy: 98.05, time: 0.22\n",
      "[58,    81] loss: 0.09736, train_accuracy: 96.68, time: 0.22\n",
      "[58,    91] loss: 0.10075, train_accuracy: 95.70, time: 0.21\n",
      "duration: 21 s - train loss: 0.09827 - train accuracy: 96.53 - validation loss: 0.64 - validation accuracy: 85.62 \n",
      "[59,     1] loss: 0.07835, train_accuracy: 96.68, time: 0.22\n",
      "[59,    11] loss: 0.09496, train_accuracy: 97.07, time: 0.22\n",
      "[59,    21] loss: 0.08488, train_accuracy: 98.05, time: 0.22\n",
      "[59,    31] loss: 0.09326, train_accuracy: 96.48, time: 0.22\n",
      "[59,    41] loss: 0.07567, train_accuracy: 96.68, time: 0.21\n",
      "[59,    51] loss: 0.07256, train_accuracy: 96.88, time: 0.22\n",
      "[59,    61] loss: 0.10870, train_accuracy: 96.68, time: 0.21\n",
      "[59,    71] loss: 0.09687, train_accuracy: 95.90, time: 0.22\n",
      "[59,    81] loss: 0.09018, train_accuracy: 96.48, time: 0.22\n",
      "[59,    91] loss: 0.09153, train_accuracy: 96.48, time: 0.21\n",
      "duration: 21 s - train loss: 0.09014 - train accuracy: 96.77 - validation loss: 0.96 - validation accuracy: 81.85 \n",
      "[60,     1] loss: 0.08495, train_accuracy: 97.07, time: 0.22\n",
      "[60,    11] loss: 0.10363, train_accuracy: 96.88, time: 0.22\n",
      "[60,    21] loss: 0.08355, train_accuracy: 97.07, time: 0.22\n",
      "[60,    31] loss: 0.07947, train_accuracy: 96.88, time: 0.22\n",
      "[60,    41] loss: 0.07911, train_accuracy: 97.85, time: 0.21\n",
      "[60,    51] loss: 0.08999, train_accuracy: 96.88, time: 0.22\n",
      "[60,    61] loss: 0.06246, train_accuracy: 97.27, time: 0.21\n",
      "[60,    71] loss: 0.06819, train_accuracy: 97.66, time: 0.21\n",
      "[60,    81] loss: 0.09220, train_accuracy: 96.68, time: 0.22\n",
      "[60,    91] loss: 0.07535, train_accuracy: 97.07, time: 0.21\n",
      "duration: 21 s - train loss: 0.09018 - train accuracy: 96.86 - validation loss: 0.68 - validation accuracy: 85.30 \n",
      "[61,     1] loss: 0.10170, train_accuracy: 96.68, time: 0.22\n",
      "[61,    11] loss: 0.07221, train_accuracy: 97.66, time: 0.21\n",
      "[61,    21] loss: 0.06490, train_accuracy: 97.66, time: 0.21\n",
      "[61,    31] loss: 0.07816, train_accuracy: 97.07, time: 0.21\n",
      "[61,    41] loss: 0.12206, train_accuracy: 94.53, time: 0.22\n",
      "[61,    51] loss: 0.05310, train_accuracy: 98.44, time: 0.22\n",
      "[61,    61] loss: 0.13004, train_accuracy: 96.29, time: 0.22\n",
      "[61,    71] loss: 0.12318, train_accuracy: 95.31, time: 0.21\n",
      "[61,    81] loss: 0.10330, train_accuracy: 97.07, time: 0.22\n",
      "[61,    91] loss: 0.10776, train_accuracy: 96.68, time: 0.21\n",
      "duration: 21 s - train loss: 0.09120 - train accuracy: 96.87 - validation loss: 1.08 - validation accuracy: 80.74 \n",
      "[62,     1] loss: 0.08071, train_accuracy: 97.27, time: 0.22\n",
      "[62,    11] loss: 0.09256, train_accuracy: 96.09, time: 0.22\n",
      "[62,    21] loss: 0.06807, train_accuracy: 98.24, time: 0.21\n",
      "[62,    31] loss: 0.08440, train_accuracy: 96.48, time: 0.22\n",
      "[62,    41] loss: 0.07254, train_accuracy: 96.88, time: 0.22\n",
      "[62,    51] loss: 0.09613, train_accuracy: 96.29, time: 0.22\n",
      "[62,    61] loss: 0.09650, train_accuracy: 96.68, time: 0.22\n",
      "[62,    71] loss: 0.07447, train_accuracy: 98.24, time: 0.22\n",
      "[62,    81] loss: 0.12051, train_accuracy: 95.90, time: 0.22\n",
      "[62,    91] loss: 0.05834, train_accuracy: 98.44, time: 0.21\n",
      "duration: 21 s - train loss: 0.08805 - train accuracy: 97.00 - validation loss: 0.96 - validation accuracy: 82.73 \n",
      "[63,     1] loss: 0.11164, train_accuracy: 96.29, time: 0.22\n",
      "[63,    11] loss: 0.07238, train_accuracy: 97.07, time: 0.22\n",
      "[63,    21] loss: 0.10898, train_accuracy: 95.90, time: 0.22\n",
      "[63,    31] loss: 0.07338, train_accuracy: 97.07, time: 0.22\n",
      "[63,    41] loss: 0.06379, train_accuracy: 97.27, time: 0.22\n",
      "[63,    51] loss: 0.06874, train_accuracy: 97.46, time: 0.21\n",
      "[63,    61] loss: 0.10979, train_accuracy: 96.09, time: 0.21\n",
      "[63,    71] loss: 0.09970, train_accuracy: 96.68, time: 0.22\n",
      "[63,    81] loss: 0.11807, train_accuracy: 96.29, time: 0.22\n",
      "[63,    91] loss: 0.06075, train_accuracy: 97.07, time: 0.22\n",
      "duration: 21 s - train loss: 0.08326 - train accuracy: 97.05 - validation loss: 1.13 - validation accuracy: 81.11 \n",
      "[64,     1] loss: 0.08616, train_accuracy: 96.68, time: 0.22\n",
      "[64,    11] loss: 0.09925, train_accuracy: 96.68, time: 0.21\n",
      "[64,    21] loss: 0.06780, train_accuracy: 97.66, time: 0.22\n",
      "[64,    31] loss: 0.08352, train_accuracy: 97.27, time: 0.22\n",
      "[64,    41] loss: 0.06477, train_accuracy: 97.27, time: 0.22\n",
      "[64,    51] loss: 0.05466, train_accuracy: 98.44, time: 0.22\n",
      "[64,    61] loss: 0.10298, train_accuracy: 96.29, time: 0.21\n",
      "[64,    71] loss: 0.07444, train_accuracy: 97.46, time: 0.22\n",
      "[64,    81] loss: 0.05785, train_accuracy: 98.24, time: 0.22\n",
      "[64,    91] loss: 0.06545, train_accuracy: 96.68, time: 0.21\n",
      "duration: 21 s - train loss: 0.08253 - train accuracy: 97.07 - validation loss: 0.82 - validation accuracy: 84.43 \n",
      "[65,     1] loss: 0.09211, train_accuracy: 97.07, time: 0.22\n",
      "[65,    11] loss: 0.04891, train_accuracy: 98.44, time: 0.22\n",
      "[65,    21] loss: 0.07276, train_accuracy: 97.85, time: 0.22\n",
      "[65,    31] loss: 0.05090, train_accuracy: 98.24, time: 0.21\n",
      "[65,    41] loss: 0.06468, train_accuracy: 97.27, time: 0.21\n",
      "[65,    51] loss: 0.06650, train_accuracy: 97.46, time: 0.21\n",
      "[65,    61] loss: 0.06503, train_accuracy: 98.05, time: 0.22\n",
      "[65,    71] loss: 0.10332, train_accuracy: 96.48, time: 0.21\n",
      "[65,    81] loss: 0.09878, train_accuracy: 96.48, time: 0.22\n",
      "[65,    91] loss: 0.08193, train_accuracy: 97.07, time: 0.22\n",
      "duration: 21 s - train loss: 0.08153 - train accuracy: 97.16 - validation loss: 0.93 - validation accuracy: 83.64 \n",
      "[66,     1] loss: 0.11231, train_accuracy: 96.88, time: 0.21\n",
      "[66,    11] loss: 0.08830, train_accuracy: 96.68, time: 0.21\n",
      "[66,    21] loss: 0.10454, train_accuracy: 95.90, time: 0.22\n",
      "[66,    31] loss: 0.06060, train_accuracy: 98.24, time: 0.22\n",
      "[66,    41] loss: 0.04616, train_accuracy: 98.24, time: 0.22\n",
      "[66,    51] loss: 0.07264, train_accuracy: 97.66, time: 0.22\n",
      "[66,    61] loss: 0.08166, train_accuracy: 96.88, time: 0.21\n",
      "[66,    71] loss: 0.04979, train_accuracy: 98.05, time: 0.22\n",
      "[66,    81] loss: 0.12450, train_accuracy: 94.73, time: 0.21\n",
      "[66,    91] loss: 0.08231, train_accuracy: 96.88, time: 0.22\n",
      "duration: 21 s - train loss: 0.07980 - train accuracy: 97.21 - validation loss: 0.82 - validation accuracy: 84.03 \n",
      "[67,     1] loss: 0.05828, train_accuracy: 98.63, time: 0.22\n",
      "[67,    11] loss: 0.09991, train_accuracy: 96.29, time: 0.22\n",
      "[67,    21] loss: 0.09361, train_accuracy: 96.68, time: 0.21\n",
      "[67,    31] loss: 0.07097, train_accuracy: 97.27, time: 0.22\n",
      "[67,    41] loss: 0.05535, train_accuracy: 98.24, time: 0.22\n",
      "[67,    51] loss: 0.09372, train_accuracy: 96.68, time: 0.22\n",
      "[67,    61] loss: 0.07912, train_accuracy: 97.07, time: 0.22\n",
      "[67,    71] loss: 0.08906, train_accuracy: 97.85, time: 0.22\n",
      "[67,    81] loss: 0.07866, train_accuracy: 97.27, time: 0.22\n",
      "[67,    91] loss: 0.07509, train_accuracy: 98.24, time: 0.22\n",
      "duration: 21 s - train loss: 0.08536 - train accuracy: 97.11 - validation loss: 1.13 - validation accuracy: 79.92 \n",
      "[68,     1] loss: 0.08014, train_accuracy: 97.27, time: 0.22\n",
      "[68,    11] loss: 0.07367, train_accuracy: 97.66, time: 0.22\n",
      "[68,    21] loss: 0.07444, train_accuracy: 96.68, time: 0.21\n",
      "[68,    31] loss: 0.05615, train_accuracy: 98.05, time: 0.22\n",
      "[68,    41] loss: 0.04175, train_accuracy: 98.83, time: 0.22\n",
      "[68,    51] loss: 0.05242, train_accuracy: 98.44, time: 0.22\n",
      "[68,    61] loss: 0.06522, train_accuracy: 97.66, time: 0.21\n",
      "[68,    71] loss: 0.07838, train_accuracy: 97.46, time: 0.21\n",
      "[68,    81] loss: 0.03851, train_accuracy: 98.24, time: 0.22\n",
      "[68,    91] loss: 0.10906, train_accuracy: 96.29, time: 0.21\n",
      "duration: 21 s - train loss: 0.07335 - train accuracy: 97.45 - validation loss: 0.93 - validation accuracy: 83.57 \n",
      "[69,     1] loss: 0.10905, train_accuracy: 96.88, time: 0.22\n",
      "[69,    11] loss: 0.10153, train_accuracy: 96.68, time: 0.22\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[69,    21] loss: 0.06560, train_accuracy: 98.24, time: 0.21\n",
      "[69,    31] loss: 0.07181, train_accuracy: 96.68, time: 0.22\n",
      "[69,    41] loss: 0.08324, train_accuracy: 97.66, time: 0.22\n",
      "[69,    51] loss: 0.06328, train_accuracy: 97.66, time: 0.22\n",
      "[69,    61] loss: 0.05066, train_accuracy: 98.05, time: 0.22\n",
      "[69,    71] loss: 0.10185, train_accuracy: 96.29, time: 0.22\n",
      "[69,    81] loss: 0.05843, train_accuracy: 97.85, time: 0.21\n",
      "[69,    91] loss: 0.07956, train_accuracy: 97.07, time: 0.22\n",
      "duration: 21 s - train loss: 0.07911 - train accuracy: 97.29 - validation loss: 1.09 - validation accuracy: 81.60 \n",
      "[70,     1] loss: 0.06561, train_accuracy: 97.27, time: 0.22\n",
      "[70,    11] loss: 0.12023, train_accuracy: 95.51, time: 0.22\n",
      "[70,    21] loss: 0.08062, train_accuracy: 97.66, time: 0.22\n",
      "[70,    31] loss: 0.07498, train_accuracy: 97.85, time: 0.21\n",
      "[70,    41] loss: 0.11229, train_accuracy: 95.90, time: 0.22\n",
      "[70,    51] loss: 0.08267, train_accuracy: 96.68, time: 0.22\n",
      "[70,    61] loss: 0.07575, train_accuracy: 97.46, time: 0.21\n",
      "[70,    71] loss: 0.05294, train_accuracy: 97.66, time: 0.22\n",
      "[70,    81] loss: 0.08196, train_accuracy: 97.27, time: 0.22\n",
      "[70,    91] loss: 0.09805, train_accuracy: 96.68, time: 0.21\n",
      "duration: 21 s - train loss: 0.07647 - train accuracy: 97.39 - validation loss: 0.88 - validation accuracy: 83.33 \n",
      "[71,     1] loss: 0.05131, train_accuracy: 98.44, time: 0.22\n",
      "[71,    11] loss: 0.04977, train_accuracy: 98.83, time: 0.21\n",
      "[71,    21] loss: 0.07701, train_accuracy: 97.66, time: 0.22\n",
      "[71,    31] loss: 0.05774, train_accuracy: 98.05, time: 0.22\n",
      "[71,    41] loss: 0.05990, train_accuracy: 98.05, time: 0.21\n",
      "[71,    51] loss: 0.07102, train_accuracy: 97.85, time: 0.22\n",
      "[71,    61] loss: 0.09164, train_accuracy: 96.29, time: 0.21\n",
      "[71,    71] loss: 0.06396, train_accuracy: 97.46, time: 0.21\n",
      "[71,    81] loss: 0.07769, train_accuracy: 98.05, time: 0.22\n",
      "[71,    91] loss: 0.07426, train_accuracy: 97.85, time: 0.22\n",
      "duration: 21 s - train loss: 0.07623 - train accuracy: 97.45 - validation loss: 1.05 - validation accuracy: 81.67 \n",
      "[72,     1] loss: 0.06022, train_accuracy: 98.24, time: 0.22\n",
      "[72,    11] loss: 0.10840, train_accuracy: 95.70, time: 0.22\n",
      "[72,    21] loss: 0.06616, train_accuracy: 97.85, time: 0.22\n",
      "[72,    31] loss: 0.08623, train_accuracy: 97.85, time: 0.21\n",
      "[72,    41] loss: 0.06676, train_accuracy: 97.85, time: 0.21\n",
      "[72,    51] loss: 0.07655, train_accuracy: 97.27, time: 0.22\n",
      "[72,    61] loss: 0.10196, train_accuracy: 97.46, time: 0.22\n",
      "[72,    71] loss: 0.06804, train_accuracy: 97.85, time: 0.21\n",
      "[72,    81] loss: 0.06264, train_accuracy: 97.66, time: 0.21\n",
      "[72,    91] loss: 0.06396, train_accuracy: 97.85, time: 0.22\n",
      "duration: 21 s - train loss: 0.08079 - train accuracy: 97.31 - validation loss: 0.89 - validation accuracy: 83.68 \n",
      "[73,     1] loss: 0.05281, train_accuracy: 97.85, time: 0.22\n",
      "[73,    11] loss: 0.04531, train_accuracy: 98.44, time: 0.22\n",
      "[73,    21] loss: 0.06667, train_accuracy: 97.07, time: 0.21\n",
      "[73,    31] loss: 0.05111, train_accuracy: 98.05, time: 0.21\n",
      "[73,    41] loss: 0.04624, train_accuracy: 98.63, time: 0.22\n",
      "[73,    51] loss: 0.11805, train_accuracy: 95.70, time: 0.22\n",
      "[73,    61] loss: 0.03844, train_accuracy: 98.63, time: 0.22\n",
      "[73,    71] loss: 0.05740, train_accuracy: 97.66, time: 0.22\n",
      "[73,    81] loss: 0.07729, train_accuracy: 97.46, time: 0.22\n",
      "[73,    91] loss: 0.03846, train_accuracy: 98.63, time: 0.22\n",
      "duration: 21 s - train loss: 0.06374 - train accuracy: 97.77 - validation loss: 1.16 - validation accuracy: 81.52 \n",
      "[74,     1] loss: 0.06348, train_accuracy: 97.46, time: 0.22\n",
      "[74,    11] loss: 0.06964, train_accuracy: 98.05, time: 0.21\n",
      "[74,    21] loss: 0.05221, train_accuracy: 98.83, time: 0.22\n",
      "[74,    31] loss: 0.06409, train_accuracy: 97.66, time: 0.21\n",
      "[74,    41] loss: 0.10176, train_accuracy: 96.88, time: 0.22\n",
      "[74,    51] loss: 0.06321, train_accuracy: 98.44, time: 0.21\n",
      "[74,    61] loss: 0.06519, train_accuracy: 97.66, time: 0.22\n",
      "[74,    71] loss: 0.11778, train_accuracy: 96.29, time: 0.21\n",
      "[74,    81] loss: 0.14197, train_accuracy: 95.70, time: 0.22\n",
      "[74,    91] loss: 0.06334, train_accuracy: 97.66, time: 0.21\n",
      "duration: 21 s - train loss: 0.06701 - train accuracy: 97.65 - validation loss: 0.83 - validation accuracy: 85.34 \n",
      "[75,     1] loss: 0.07130, train_accuracy: 97.66, time: 0.22\n",
      "[75,    11] loss: 0.04851, train_accuracy: 98.63, time: 0.22\n",
      "[75,    21] loss: 0.05239, train_accuracy: 97.85, time: 0.22\n",
      "[75,    31] loss: 0.04883, train_accuracy: 98.44, time: 0.21\n",
      "[75,    41] loss: 0.07721, train_accuracy: 97.27, time: 0.22\n",
      "[75,    51] loss: 0.11252, train_accuracy: 96.68, time: 0.22\n",
      "[75,    61] loss: 0.04881, train_accuracy: 97.85, time: 0.21\n",
      "[75,    71] loss: 0.07745, train_accuracy: 97.27, time: 0.22\n",
      "[75,    81] loss: 0.04218, train_accuracy: 98.24, time: 0.21\n",
      "[75,    91] loss: 0.05808, train_accuracy: 98.63, time: 0.22\n",
      "duration: 21 s - train loss: 0.06913 - train accuracy: 97.64 - validation loss: 0.92 - validation accuracy: 84.23 \n",
      "[76,     1] loss: 0.06221, train_accuracy: 97.27, time: 0.21\n",
      "[76,    11] loss: 0.07047, train_accuracy: 97.66, time: 0.21\n",
      "[76,    21] loss: 0.03794, train_accuracy: 98.83, time: 0.21\n",
      "[76,    31] loss: 0.06178, train_accuracy: 97.46, time: 0.21\n",
      "[76,    41] loss: 0.05406, train_accuracy: 97.85, time: 0.22\n",
      "[76,    51] loss: 0.05848, train_accuracy: 98.24, time: 0.22\n",
      "[76,    61] loss: 0.11602, train_accuracy: 96.48, time: 0.21\n",
      "[76,    71] loss: 0.08565, train_accuracy: 97.46, time: 0.21\n",
      "[76,    81] loss: 0.06056, train_accuracy: 98.24, time: 0.22\n",
      "[76,    91] loss: 0.07250, train_accuracy: 98.44, time: 0.21\n",
      "duration: 21 s - train loss: 0.06813 - train accuracy: 97.67 - validation loss: 0.87 - validation accuracy: 84.76 \n",
      "[77,     1] loss: 0.07257, train_accuracy: 97.46, time: 0.22\n",
      "[77,    11] loss: 0.08429, train_accuracy: 97.46, time: 0.22\n",
      "[77,    21] loss: 0.04260, train_accuracy: 98.63, time: 0.22\n",
      "[77,    31] loss: 0.10760, train_accuracy: 96.48, time: 0.22\n",
      "[77,    41] loss: 0.05997, train_accuracy: 97.66, time: 0.22\n",
      "[77,    51] loss: 0.07868, train_accuracy: 97.85, time: 0.21\n",
      "[77,    61] loss: 0.05958, train_accuracy: 97.66, time: 0.21\n",
      "[77,    71] loss: 0.07922, train_accuracy: 97.66, time: 0.21\n",
      "[77,    81] loss: 0.10945, train_accuracy: 96.29, time: 0.21\n",
      "[77,    91] loss: 0.05287, train_accuracy: 98.83, time: 0.22\n",
      "duration: 21 s - train loss: 0.06712 - train accuracy: 97.72 - validation loss: 0.94 - validation accuracy: 83.92 \n",
      "[78,     1] loss: 0.09668, train_accuracy: 97.66, time: 0.22\n",
      "[78,    11] loss: 0.06125, train_accuracy: 97.85, time: 0.22\n",
      "[78,    21] loss: 0.06008, train_accuracy: 97.85, time: 0.22\n",
      "[78,    31] loss: 0.04639, train_accuracy: 97.85, time: 0.22\n",
      "[78,    41] loss: 0.02889, train_accuracy: 98.83, time: 0.21\n",
      "[78,    51] loss: 0.04997, train_accuracy: 98.05, time: 0.22\n",
      "[78,    61] loss: 0.09627, train_accuracy: 97.07, time: 0.22\n",
      "[78,    71] loss: 0.05840, train_accuracy: 98.24, time: 0.21\n",
      "[78,    81] loss: 0.06506, train_accuracy: 97.66, time: 0.21\n",
      "[78,    91] loss: 0.07834, train_accuracy: 97.07, time: 0.22\n",
      "duration: 21 s - train loss: 0.06050 - train accuracy: 97.97 - validation loss: 0.94 - validation accuracy: 83.90 \n",
      "[79,     1] loss: 0.04600, train_accuracy: 98.83, time: 0.22\n",
      "[79,    11] loss: 0.04863, train_accuracy: 98.63, time: 0.22\n",
      "[79,    21] loss: 0.06114, train_accuracy: 97.46, time: 0.21\n",
      "[79,    31] loss: 0.06433, train_accuracy: 97.46, time: 0.23\n",
      "[79,    41] loss: 0.05852, train_accuracy: 98.05, time: 0.21\n",
      "[79,    51] loss: 0.06522, train_accuracy: 98.24, time: 0.21\n",
      "[79,    61] loss: 0.05891, train_accuracy: 98.05, time: 0.22\n",
      "[79,    71] loss: 0.04741, train_accuracy: 97.66, time: 0.21\n",
      "[79,    81] loss: 0.06008, train_accuracy: 98.05, time: 0.22\n",
      "[79,    91] loss: 0.07391, train_accuracy: 97.66, time: 0.21\n",
      "duration: 21 s - train loss: 0.06493 - train accuracy: 97.79 - validation loss: 0.92 - validation accuracy: 83.53 \n",
      "[80,     1] loss: 0.03754, train_accuracy: 99.22, time: 0.22\n",
      "[80,    11] loss: 0.06264, train_accuracy: 97.27, time: 0.21\n",
      "[80,    21] loss: 0.03068, train_accuracy: 99.22, time: 0.22\n",
      "[80,    31] loss: 0.06637, train_accuracy: 97.66, time: 0.22\n",
      "[80,    41] loss: 0.04837, train_accuracy: 97.66, time: 0.21\n",
      "[80,    51] loss: 0.06600, train_accuracy: 97.07, time: 0.22\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[80,    61] loss: 0.05663, train_accuracy: 97.46, time: 0.21\n",
      "[80,    71] loss: 0.05860, train_accuracy: 98.05, time: 0.21\n",
      "[80,    81] loss: 0.05521, train_accuracy: 98.44, time: 0.22\n",
      "[80,    91] loss: 0.04316, train_accuracy: 98.05, time: 0.24\n",
      "duration: 21 s - train loss: 0.05957 - train accuracy: 97.91 - validation loss: 0.90 - validation accuracy: 84.93 \n",
      "[81,     1] loss: 0.06014, train_accuracy: 98.05, time: 0.22\n",
      "[81,    11] loss: 0.07466, train_accuracy: 97.46, time: 0.21\n",
      "[81,    21] loss: 0.06304, train_accuracy: 98.63, time: 0.22\n",
      "[81,    31] loss: 0.10172, train_accuracy: 96.68, time: 0.22\n",
      "[81,    41] loss: 0.04484, train_accuracy: 98.83, time: 0.22\n",
      "[81,    51] loss: 0.05833, train_accuracy: 98.44, time: 0.22\n",
      "[81,    61] loss: 0.02482, train_accuracy: 99.61, time: 0.22\n",
      "[81,    71] loss: 0.09741, train_accuracy: 97.07, time: 0.21\n",
      "[81,    81] loss: 0.11929, train_accuracy: 97.46, time: 0.22\n",
      "[81,    91] loss: 0.05356, train_accuracy: 98.44, time: 0.22\n",
      "duration: 21 s - train loss: 0.06041 - train accuracy: 97.98 - validation loss: 1.08 - validation accuracy: 82.42 \n",
      "[82,     1] loss: 0.07110, train_accuracy: 97.66, time: 0.22\n",
      "[82,    11] loss: 0.06065, train_accuracy: 98.24, time: 0.22\n",
      "[82,    21] loss: 0.05864, train_accuracy: 97.85, time: 0.22\n",
      "[82,    31] loss: 0.10381, train_accuracy: 97.07, time: 0.24\n",
      "[82,    41] loss: 0.05125, train_accuracy: 97.85, time: 0.22\n",
      "[82,    51] loss: 0.06991, train_accuracy: 97.46, time: 0.22\n",
      "[82,    61] loss: 0.04618, train_accuracy: 98.63, time: 0.21\n",
      "[82,    71] loss: 0.06392, train_accuracy: 97.85, time: 0.21\n",
      "[82,    81] loss: 0.05480, train_accuracy: 98.24, time: 0.22\n",
      "[82,    91] loss: 0.07553, train_accuracy: 97.27, time: 0.21\n",
      "duration: 21 s - train loss: 0.06165 - train accuracy: 97.94 - validation loss: 0.88 - validation accuracy: 84.09 \n",
      "[83,     1] loss: 0.07548, train_accuracy: 98.05, time: 0.22\n",
      "[83,    11] loss: 0.07730, train_accuracy: 96.68, time: 0.22\n",
      "[83,    21] loss: 0.03964, train_accuracy: 98.83, time: 0.21\n",
      "[83,    31] loss: 0.03975, train_accuracy: 98.44, time: 0.21\n",
      "[83,    41] loss: 0.09644, train_accuracy: 97.07, time: 0.22\n",
      "[83,    51] loss: 0.05709, train_accuracy: 98.05, time: 0.22\n",
      "[83,    61] loss: 0.06374, train_accuracy: 97.66, time: 0.22\n",
      "[83,    71] loss: 0.07389, train_accuracy: 97.66, time: 0.21\n",
      "[83,    81] loss: 0.04110, train_accuracy: 98.24, time: 0.21\n",
      "[83,    91] loss: 0.09281, train_accuracy: 97.07, time: 0.22\n",
      "duration: 21 s - train loss: 0.06227 - train accuracy: 97.85 - validation loss: 0.86 - validation accuracy: 85.17 \n",
      "[84,     1] loss: 0.06991, train_accuracy: 97.27, time: 0.22\n",
      "[84,    11] loss: 0.03942, train_accuracy: 98.63, time: 0.21\n",
      "[84,    21] loss: 0.05527, train_accuracy: 97.85, time: 0.22\n",
      "[84,    31] loss: 0.07049, train_accuracy: 97.07, time: 0.22\n",
      "[84,    41] loss: 0.09684, train_accuracy: 96.09, time: 0.22\n",
      "[84,    51] loss: 0.06456, train_accuracy: 97.66, time: 0.21\n",
      "[84,    61] loss: 0.05245, train_accuracy: 97.85, time: 0.21\n",
      "[84,    71] loss: 0.05792, train_accuracy: 97.85, time: 0.21\n",
      "[84,    81] loss: 0.07293, train_accuracy: 97.66, time: 0.22\n",
      "[84,    91] loss: 0.08184, train_accuracy: 97.07, time: 0.22\n",
      "duration: 21 s - train loss: 0.05950 - train accuracy: 97.93 - validation loss: 0.86 - validation accuracy: 84.37 \n",
      "[85,     1] loss: 0.04010, train_accuracy: 98.44, time: 0.22\n",
      "[85,    11] loss: 0.03313, train_accuracy: 99.22, time: 0.21\n",
      "[85,    21] loss: 0.03948, train_accuracy: 99.02, time: 0.22\n",
      "[85,    31] loss: 0.04570, train_accuracy: 98.83, time: 0.22\n",
      "[85,    41] loss: 0.03475, train_accuracy: 98.63, time: 0.21\n",
      "[85,    51] loss: 0.06801, train_accuracy: 97.85, time: 0.21\n",
      "[85,    61] loss: 0.05265, train_accuracy: 99.02, time: 0.22\n",
      "[85,    71] loss: 0.05320, train_accuracy: 97.66, time: 0.22\n",
      "[85,    81] loss: 0.06466, train_accuracy: 98.44, time: 0.21\n",
      "[85,    91] loss: 0.05861, train_accuracy: 97.27, time: 0.22\n",
      "duration: 21 s - train loss: 0.05694 - train accuracy: 98.07 - validation loss: 1.00 - validation accuracy: 83.53 \n",
      "[86,     1] loss: 0.05301, train_accuracy: 98.05, time: 0.21\n",
      "[86,    11] loss: 0.05751, train_accuracy: 98.44, time: 0.21\n",
      "[86,    21] loss: 0.03327, train_accuracy: 99.41, time: 0.22\n",
      "[86,    31] loss: 0.07996, train_accuracy: 97.46, time: 0.22\n",
      "[86,    41] loss: 0.04045, train_accuracy: 98.24, time: 0.21\n",
      "[86,    51] loss: 0.05797, train_accuracy: 98.24, time: 0.21\n",
      "[86,    61] loss: 0.01938, train_accuracy: 99.41, time: 0.21\n",
      "[86,    71] loss: 0.04514, train_accuracy: 98.63, time: 0.22\n",
      "[86,    81] loss: 0.07676, train_accuracy: 97.27, time: 0.21\n",
      "[86,    91] loss: 0.04115, train_accuracy: 98.63, time: 0.21\n",
      "duration: 21 s - train loss: 0.05785 - train accuracy: 98.03 - validation loss: 1.11 - validation accuracy: 82.62 \n",
      "[87,     1] loss: 0.04508, train_accuracy: 98.24, time: 0.21\n",
      "[87,    11] loss: 0.08126, train_accuracy: 97.27, time: 0.22\n",
      "[87,    21] loss: 0.07909, train_accuracy: 96.48, time: 0.21\n",
      "[87,    31] loss: 0.06860, train_accuracy: 97.66, time: 0.22\n",
      "[87,    41] loss: 0.04808, train_accuracy: 98.44, time: 0.22\n",
      "[87,    51] loss: 0.07656, train_accuracy: 97.66, time: 0.22\n",
      "[87,    61] loss: 0.08473, train_accuracy: 97.07, time: 0.22\n",
      "[87,    71] loss: 0.05382, train_accuracy: 98.44, time: 0.22\n",
      "[87,    81] loss: 0.06127, train_accuracy: 97.85, time: 0.22\n",
      "[87,    91] loss: 0.04022, train_accuracy: 98.63, time: 0.22\n",
      "duration: 21 s - train loss: 0.06428 - train accuracy: 97.74 - validation loss: 1.15 - validation accuracy: 82.47 \n",
      "[88,     1] loss: 0.03311, train_accuracy: 99.02, time: 0.21\n",
      "[88,    11] loss: 0.03551, train_accuracy: 98.44, time: 0.22\n",
      "[88,    21] loss: 0.06951, train_accuracy: 97.66, time: 0.21\n",
      "[88,    31] loss: 0.04269, train_accuracy: 98.44, time: 0.22\n",
      "[88,    41] loss: 0.04049, train_accuracy: 98.44, time: 0.22\n",
      "[88,    51] loss: 0.11279, train_accuracy: 96.68, time: 0.22\n",
      "[88,    61] loss: 0.07187, train_accuracy: 97.66, time: 0.22\n",
      "[88,    71] loss: 0.05583, train_accuracy: 98.05, time: 0.21\n",
      "[88,    81] loss: 0.06406, train_accuracy: 97.85, time: 0.22\n",
      "[88,    91] loss: 0.06425, train_accuracy: 98.44, time: 0.21\n",
      "duration: 21 s - train loss: 0.05874 - train accuracy: 97.96 - validation loss: 0.89 - validation accuracy: 84.71 \n",
      "[89,     1] loss: 0.03964, train_accuracy: 98.63, time: 0.22\n",
      "[89,    11] loss: 0.05966, train_accuracy: 98.24, time: 0.21\n",
      "[89,    21] loss: 0.09418, train_accuracy: 97.66, time: 0.21\n",
      "[89,    31] loss: 0.09250, train_accuracy: 97.66, time: 0.22\n",
      "[89,    41] loss: 0.04855, train_accuracy: 98.24, time: 0.21\n",
      "[89,    51] loss: 0.05013, train_accuracy: 98.44, time: 0.21\n",
      "[89,    61] loss: 0.08811, train_accuracy: 96.09, time: 0.22\n",
      "[89,    71] loss: 0.03393, train_accuracy: 98.83, time: 0.21\n",
      "[89,    81] loss: 0.04885, train_accuracy: 98.24, time: 0.21\n",
      "[89,    91] loss: 0.04374, train_accuracy: 98.63, time: 0.22\n",
      "duration: 21 s - train loss: 0.05535 - train accuracy: 98.15 - validation loss: 0.92 - validation accuracy: 84.13 \n",
      "[90,     1] loss: 0.05949, train_accuracy: 97.66, time: 0.21\n",
      "[90,    11] loss: 0.05121, train_accuracy: 98.05, time: 0.22\n",
      "[90,    21] loss: 0.06950, train_accuracy: 97.27, time: 0.22\n",
      "[90,    31] loss: 0.06923, train_accuracy: 98.83, time: 0.22\n",
      "[90,    41] loss: 0.04635, train_accuracy: 98.24, time: 0.22\n",
      "[90,    51] loss: 0.03428, train_accuracy: 98.83, time: 0.22\n",
      "[90,    61] loss: 0.03118, train_accuracy: 99.02, time: 0.21\n",
      "[90,    71] loss: 0.05223, train_accuracy: 98.44, time: 0.22\n",
      "[90,    81] loss: 0.04441, train_accuracy: 98.05, time: 0.21\n",
      "[90,    91] loss: 0.03914, train_accuracy: 99.02, time: 0.22\n",
      "duration: 21 s - train loss: 0.05574 - train accuracy: 98.11 - validation loss: 1.05 - validation accuracy: 83.92 \n",
      "[91,     1] loss: 0.05534, train_accuracy: 98.63, time: 0.22\n",
      "[91,    11] loss: 0.04537, train_accuracy: 98.83, time: 0.22\n",
      "[91,    21] loss: 0.02859, train_accuracy: 99.02, time: 0.21\n",
      "[91,    31] loss: 0.06384, train_accuracy: 97.27, time: 0.22\n",
      "[91,    41] loss: 0.04226, train_accuracy: 98.63, time: 0.22\n",
      "[91,    51] loss: 0.08369, train_accuracy: 97.46, time: 0.22\n",
      "[91,    61] loss: 0.03759, train_accuracy: 98.24, time: 0.22\n",
      "[91,    71] loss: 0.04221, train_accuracy: 98.83, time: 0.21\n",
      "[91,    81] loss: 0.06340, train_accuracy: 97.85, time: 0.22\n",
      "[91,    91] loss: 0.07537, train_accuracy: 97.46, time: 0.22\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "duration: 21 s - train loss: 0.05034 - train accuracy: 98.34 - validation loss: 1.02 - validation accuracy: 83.32 \n",
      "[92,     1] loss: 0.06067, train_accuracy: 98.44, time: 0.22\n",
      "[92,    11] loss: 0.05157, train_accuracy: 98.05, time: 0.22\n",
      "[92,    21] loss: 0.03914, train_accuracy: 98.44, time: 0.22\n",
      "[92,    31] loss: 0.03496, train_accuracy: 98.83, time: 0.21\n",
      "[92,    41] loss: 0.06225, train_accuracy: 97.85, time: 0.22\n",
      "[92,    51] loss: 0.10543, train_accuracy: 96.68, time: 0.22\n",
      "[92,    61] loss: 0.04716, train_accuracy: 98.24, time: 0.22\n",
      "[92,    71] loss: 0.07610, train_accuracy: 97.85, time: 0.22\n",
      "[92,    81] loss: 0.06546, train_accuracy: 97.85, time: 0.21\n",
      "[92,    91] loss: 0.03806, train_accuracy: 98.05, time: 0.22\n",
      "duration: 21 s - train loss: 0.05596 - train accuracy: 98.12 - validation loss: 1.01 - validation accuracy: 84.08 \n",
      "[93,     1] loss: 0.05653, train_accuracy: 98.24, time: 0.22\n",
      "[93,    11] loss: 0.03948, train_accuracy: 98.63, time: 0.22\n",
      "[93,    21] loss: 0.05557, train_accuracy: 97.66, time: 0.21\n",
      "[93,    31] loss: 0.05005, train_accuracy: 98.83, time: 0.22\n",
      "[93,    41] loss: 0.05441, train_accuracy: 98.63, time: 0.22\n",
      "[93,    51] loss: 0.03664, train_accuracy: 97.85, time: 0.22\n",
      "[93,    61] loss: 0.04190, train_accuracy: 98.44, time: 0.22\n",
      "[93,    71] loss: 0.06943, train_accuracy: 97.66, time: 0.22\n",
      "[93,    81] loss: 0.05841, train_accuracy: 97.85, time: 0.21\n",
      "[93,    91] loss: 0.05045, train_accuracy: 98.44, time: 0.21\n",
      "duration: 21 s - train loss: 0.05379 - train accuracy: 98.19 - validation loss: 1.13 - validation accuracy: 82.37 \n",
      "[94,     1] loss: 0.02509, train_accuracy: 99.02, time: 0.22\n",
      "[94,    11] loss: 0.07251, train_accuracy: 96.88, time: 0.21\n",
      "[94,    21] loss: 0.02056, train_accuracy: 99.41, time: 0.22\n",
      "[94,    31] loss: 0.05008, train_accuracy: 98.44, time: 0.21\n",
      "[94,    41] loss: 0.04835, train_accuracy: 98.44, time: 0.22\n",
      "[94,    51] loss: 0.09037, train_accuracy: 97.07, time: 0.21\n",
      "[94,    61] loss: 0.08753, train_accuracy: 96.68, time: 0.21\n",
      "[94,    71] loss: 0.04976, train_accuracy: 98.05, time: 0.22\n",
      "[94,    81] loss: 0.03947, train_accuracy: 98.05, time: 0.22\n",
      "[94,    91] loss: 0.04209, train_accuracy: 98.44, time: 0.22\n",
      "duration: 21 s - train loss: 0.05362 - train accuracy: 98.15 - validation loss: 1.00 - validation accuracy: 84.54 \n",
      "[95,     1] loss: 0.08498, train_accuracy: 96.68, time: 0.22\n",
      "[95,    11] loss: 0.04456, train_accuracy: 98.24, time: 0.22\n",
      "[95,    21] loss: 0.04956, train_accuracy: 98.24, time: 0.22\n",
      "[95,    31] loss: 0.01990, train_accuracy: 99.41, time: 0.21\n",
      "[95,    41] loss: 0.03670, train_accuracy: 99.02, time: 0.22\n",
      "[95,    51] loss: 0.09069, train_accuracy: 97.27, time: 0.22\n",
      "[95,    61] loss: 0.02613, train_accuracy: 99.22, time: 0.22\n",
      "[95,    71] loss: 0.03038, train_accuracy: 98.44, time: 0.22\n",
      "[95,    81] loss: 0.03461, train_accuracy: 98.24, time: 0.22\n",
      "[95,    91] loss: 0.05637, train_accuracy: 97.66, time: 0.21\n",
      "duration: 21 s - train loss: 0.05023 - train accuracy: 98.30 - validation loss: 0.82 - validation accuracy: 85.67 \n",
      "[96,     1] loss: 0.03441, train_accuracy: 98.44, time: 0.21\n",
      "[96,    11] loss: 0.03879, train_accuracy: 99.02, time: 0.21\n",
      "[96,    21] loss: 0.04094, train_accuracy: 98.05, time: 0.22\n",
      "[96,    31] loss: 0.02557, train_accuracy: 99.02, time: 0.22\n",
      "[96,    41] loss: 0.03531, train_accuracy: 99.02, time: 0.22\n",
      "[96,    51] loss: 0.06286, train_accuracy: 97.85, time: 0.21\n",
      "[96,    61] loss: 0.04199, train_accuracy: 98.24, time: 0.21\n",
      "[96,    71] loss: 0.02188, train_accuracy: 99.41, time: 0.22\n",
      "[96,    81] loss: 0.07444, train_accuracy: 97.85, time: 0.22\n",
      "[96,    91] loss: 0.04758, train_accuracy: 98.44, time: 0.22\n",
      "duration: 21 s - train loss: 0.04902 - train accuracy: 98.31 - validation loss: 1.08 - validation accuracy: 83.73 \n",
      "[97,     1] loss: 0.03749, train_accuracy: 99.22, time: 0.22\n",
      "[97,    11] loss: 0.06309, train_accuracy: 98.05, time: 0.21\n",
      "[97,    21] loss: 0.04770, train_accuracy: 98.05, time: 0.22\n",
      "[97,    31] loss: 0.05265, train_accuracy: 98.24, time: 0.22\n",
      "[97,    41] loss: 0.05452, train_accuracy: 98.24, time: 0.22\n",
      "[97,    51] loss: 0.03564, train_accuracy: 99.02, time: 0.21\n",
      "[97,    61] loss: 0.07086, train_accuracy: 97.46, time: 0.21\n",
      "[97,    71] loss: 0.05833, train_accuracy: 98.24, time: 0.21\n",
      "[97,    81] loss: 0.03841, train_accuracy: 98.83, time: 0.21\n",
      "[97,    91] loss: 0.05067, train_accuracy: 98.24, time: 0.21\n",
      "duration: 21 s - train loss: 0.05277 - train accuracy: 98.25 - validation loss: 0.96 - validation accuracy: 85.57 \n",
      "[98,     1] loss: 0.07010, train_accuracy: 97.85, time: 0.21\n",
      "[98,    11] loss: 0.04992, train_accuracy: 98.63, time: 0.22\n",
      "[98,    21] loss: 0.03408, train_accuracy: 99.02, time: 0.21\n",
      "[98,    31] loss: 0.03873, train_accuracy: 98.24, time: 0.22\n",
      "[98,    41] loss: 0.03574, train_accuracy: 98.24, time: 0.22\n",
      "[98,    51] loss: 0.04812, train_accuracy: 98.63, time: 0.21\n",
      "[98,    61] loss: 0.06425, train_accuracy: 98.05, time: 0.22\n",
      "[98,    71] loss: 0.05334, train_accuracy: 98.44, time: 0.22\n",
      "[98,    81] loss: 0.03761, train_accuracy: 98.24, time: 0.22\n",
      "[98,    91] loss: 0.08366, train_accuracy: 98.05, time: 0.22\n",
      "duration: 21 s - train loss: 0.05266 - train accuracy: 98.26 - validation loss: 0.98 - validation accuracy: 84.10 \n",
      "[99,     1] loss: 0.04601, train_accuracy: 98.05, time: 0.22\n",
      "[99,    11] loss: 0.03552, train_accuracy: 98.63, time: 0.22\n",
      "[99,    21] loss: 0.05893, train_accuracy: 97.66, time: 0.21\n",
      "[99,    31] loss: 0.03476, train_accuracy: 98.83, time: 0.22\n",
      "[99,    41] loss: 0.04532, train_accuracy: 98.05, time: 0.22\n",
      "[99,    51] loss: 0.08790, train_accuracy: 96.68, time: 0.22\n",
      "[99,    61] loss: 0.03095, train_accuracy: 98.63, time: 0.21\n",
      "[99,    71] loss: 0.03464, train_accuracy: 98.24, time: 0.22\n",
      "[99,    81] loss: 0.02956, train_accuracy: 98.83, time: 0.22\n",
      "[99,    91] loss: 0.05178, train_accuracy: 97.46, time: 0.22\n",
      "duration: 21 s - train loss: 0.04998 - train accuracy: 98.29 - validation loss: 0.79 - validation accuracy: 86.56 \n",
      "[100,     1] loss: 0.03256, train_accuracy: 98.44, time: 0.22\n",
      "[100,    11] loss: 0.05900, train_accuracy: 98.05, time: 0.21\n",
      "[100,    21] loss: 0.05674, train_accuracy: 98.63, time: 0.21\n",
      "[100,    31] loss: 0.02828, train_accuracy: 99.22, time: 0.22\n",
      "[100,    41] loss: 0.03622, train_accuracy: 98.83, time: 0.22\n",
      "[100,    51] loss: 0.05845, train_accuracy: 98.24, time: 0.21\n",
      "[100,    61] loss: 0.05302, train_accuracy: 98.44, time: 0.21\n",
      "[100,    71] loss: 0.05395, train_accuracy: 98.44, time: 0.22\n",
      "[100,    81] loss: 0.03653, train_accuracy: 98.83, time: 0.22\n",
      "[100,    91] loss: 0.04556, train_accuracy: 98.83, time: 0.22\n",
      "duration: 21 s - train loss: 0.04954 - train accuracy: 98.33 - validation loss: 1.17 - validation accuracy: 83.21 \n",
      "Finished Training\n",
      "CPU times: user 36min 56s, sys: 22.3 s, total: 37min 18s\n",
      "Wall time: 37min 40s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>train_accuracy</th>\n",
       "      <th>validation_loss</th>\n",
       "      <th>validation_accuracy</th>\n",
       "      <th>duration</th>\n",
       "      <th>criterion</th>\n",
       "      <th>optimizer</th>\n",
       "      <th>method</th>\n",
       "      <th>batchsize</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2.196176</td>\n",
       "      <td>25.951128</td>\n",
       "      <td>1.766533</td>\n",
       "      <td>33.61</td>\n",
       "      <td>21.328791</td>\n",
       "      <td>CrossEntropyLoss()</td>\n",
       "      <td>Adam (\\nParameter Group 0\\n    amsgrad: False\\...</td>\n",
       "      <td>standard</td>\n",
       "      <td>512.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>1.595128</td>\n",
       "      <td>40.962384</td>\n",
       "      <td>1.640888</td>\n",
       "      <td>42.39</td>\n",
       "      <td>42.681702</td>\n",
       "      <td>CrossEntropyLoss()</td>\n",
       "      <td>Adam (\\nParameter Group 0\\n    amsgrad: False\\...</td>\n",
       "      <td>standard</td>\n",
       "      <td>512.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.0</td>\n",
       "      <td>1.343528</td>\n",
       "      <td>51.022781</td>\n",
       "      <td>1.623494</td>\n",
       "      <td>47.01</td>\n",
       "      <td>64.041028</td>\n",
       "      <td>CrossEntropyLoss()</td>\n",
       "      <td>Adam (\\nParameter Group 0\\n    amsgrad: False\\...</td>\n",
       "      <td>standard</td>\n",
       "      <td>512.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.0</td>\n",
       "      <td>1.152945</td>\n",
       "      <td>58.990923</td>\n",
       "      <td>1.770410</td>\n",
       "      <td>46.16</td>\n",
       "      <td>85.327015</td>\n",
       "      <td>CrossEntropyLoss()</td>\n",
       "      <td>Adam (\\nParameter Group 0\\n    amsgrad: False\\...</td>\n",
       "      <td>standard</td>\n",
       "      <td>512.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>1.011138</td>\n",
       "      <td>64.042191</td>\n",
       "      <td>1.212974</td>\n",
       "      <td>60.79</td>\n",
       "      <td>106.638274</td>\n",
       "      <td>CrossEntropyLoss()</td>\n",
       "      <td>Adam (\\nParameter Group 0\\n    amsgrad: False\\...</td>\n",
       "      <td>standard</td>\n",
       "      <td>512.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>96.0</td>\n",
       "      <td>0.049020</td>\n",
       "      <td>98.313745</td>\n",
       "      <td>1.075013</td>\n",
       "      <td>83.73</td>\n",
       "      <td>2049.109720</td>\n",
       "      <td>CrossEntropyLoss()</td>\n",
       "      <td>Adam (\\nParameter Group 0\\n    amsgrad: False\\...</td>\n",
       "      <td>standard</td>\n",
       "      <td>512.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>97.0</td>\n",
       "      <td>0.052766</td>\n",
       "      <td>98.246743</td>\n",
       "      <td>0.957367</td>\n",
       "      <td>85.57</td>\n",
       "      <td>2070.442676</td>\n",
       "      <td>CrossEntropyLoss()</td>\n",
       "      <td>Adam (\\nParameter Group 0\\n    amsgrad: False\\...</td>\n",
       "      <td>standard</td>\n",
       "      <td>512.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>98.0</td>\n",
       "      <td>0.052664</td>\n",
       "      <td>98.261833</td>\n",
       "      <td>0.980498</td>\n",
       "      <td>84.10</td>\n",
       "      <td>2091.747197</td>\n",
       "      <td>CrossEntropyLoss()</td>\n",
       "      <td>Adam (\\nParameter Group 0\\n    amsgrad: False\\...</td>\n",
       "      <td>standard</td>\n",
       "      <td>512.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>99.0</td>\n",
       "      <td>0.049976</td>\n",
       "      <td>98.292582</td>\n",
       "      <td>0.794041</td>\n",
       "      <td>86.56</td>\n",
       "      <td>2113.115365</td>\n",
       "      <td>CrossEntropyLoss()</td>\n",
       "      <td>Adam (\\nParameter Group 0\\n    amsgrad: False\\...</td>\n",
       "      <td>standard</td>\n",
       "      <td>512.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>100.0</td>\n",
       "      <td>0.049542</td>\n",
       "      <td>98.334434</td>\n",
       "      <td>1.170134</td>\n",
       "      <td>83.21</td>\n",
       "      <td>2134.481272</td>\n",
       "      <td>CrossEntropyLoss()</td>\n",
       "      <td>Adam (\\nParameter Group 0\\n    amsgrad: False\\...</td>\n",
       "      <td>standard</td>\n",
       "      <td>512.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows  10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    epoch  train_loss  train_accuracy  validation_loss  validation_accuracy  \\\n",
       "0     1.0    2.196176       25.951128         1.766533                33.61   \n",
       "1     2.0    1.595128       40.962384         1.640888                42.39   \n",
       "2     3.0    1.343528       51.022781         1.623494                47.01   \n",
       "3     4.0    1.152945       58.990923         1.770410                46.16   \n",
       "4     5.0    1.011138       64.042191         1.212974                60.79   \n",
       "..    ...         ...             ...              ...                  ...   \n",
       "95   96.0    0.049020       98.313745         1.075013                83.73   \n",
       "96   97.0    0.052766       98.246743         0.957367                85.57   \n",
       "97   98.0    0.052664       98.261833         0.980498                84.10   \n",
       "98   99.0    0.049976       98.292582         0.794041                86.56   \n",
       "99  100.0    0.049542       98.334434         1.170134                83.21   \n",
       "\n",
       "       duration           criterion  \\\n",
       "0     21.328791  CrossEntropyLoss()   \n",
       "1     42.681702  CrossEntropyLoss()   \n",
       "2     64.041028  CrossEntropyLoss()   \n",
       "3     85.327015  CrossEntropyLoss()   \n",
       "4    106.638274  CrossEntropyLoss()   \n",
       "..          ...                 ...   \n",
       "95  2049.109720  CrossEntropyLoss()   \n",
       "96  2070.442676  CrossEntropyLoss()   \n",
       "97  2091.747197  CrossEntropyLoss()   \n",
       "98  2113.115365  CrossEntropyLoss()   \n",
       "99  2134.481272  CrossEntropyLoss()   \n",
       "\n",
       "                                            optimizer    method  batchsize  \n",
       "0   Adam (\\nParameter Group 0\\n    amsgrad: False\\...  standard      512.0  \n",
       "1   Adam (\\nParameter Group 0\\n    amsgrad: False\\...  standard      512.0  \n",
       "2   Adam (\\nParameter Group 0\\n    amsgrad: False\\...  standard      512.0  \n",
       "3   Adam (\\nParameter Group 0\\n    amsgrad: False\\...  standard      512.0  \n",
       "4   Adam (\\nParameter Group 0\\n    amsgrad: False\\...  standard      512.0  \n",
       "..                                                ...       ...        ...  \n",
       "95  Adam (\\nParameter Group 0\\n    amsgrad: False\\...  standard      512.0  \n",
       "96  Adam (\\nParameter Group 0\\n    amsgrad: False\\...  standard      512.0  \n",
       "97  Adam (\\nParameter Group 0\\n    amsgrad: False\\...  standard      512.0  \n",
       "98  Adam (\\nParameter Group 0\\n    amsgrad: False\\...  standard      512.0  \n",
       "99  Adam (\\nParameter Group 0\\n    amsgrad: False\\...  standard      512.0  \n",
       "\n",
       "[100 rows x 10 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "_fit(m, train_dl, val_dl, 100, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from . helpers import _craft_advs, _evaluate_model\n",
    "\n",
    "def _fit(model, train_loader, val_loader, epochs, device, patience=None, evaluate_robustness=False):\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters())\n",
    "    \n",
    "    train_stats=pd.DataFrame([])\n",
    "    total_time = 0\n",
    "    epochs_trained = 0\n",
    "    train_loss_hist, train_acc_hist, val_loss_hist, val_acc_hist = [], [], [], []\n",
    "    for epoch in range(epochs):  # loop over the dataset multiple times\n",
    "        t0 = time.time()\n",
    "        acc_epoch_loss, avg_epoch_loss, epoch_accuracy, acc_epoch_accuracy = 0.0, 0.0, 0.0, 0.0\n",
    "        \n",
    "        \n",
    "        for i, data in enumerate(train_loader, 0):\n",
    "            t00 = time.time()\n",
    "            inputs, labels = data\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # forward + backward + optimize\n",
    "            outputs = model(inputs)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "\n",
    "            batchsize = labels.size(0)\n",
    "            correct = (predicted == labels).sum().item()\n",
    "            accuracy = 100 * correct / batchsize\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "                # print statistics\n",
    "            acc_epoch_loss += loss.item() \n",
    "            avg_epoch_loss = acc_epoch_loss / (i+1)\n",
    "            acc_epoch_accuracy += accuracy\n",
    "            avg_epoch_accuracy = acc_epoch_accuracy / (i+1)\n",
    "            t11 = time.time()\n",
    "            if i%10 == 0:\n",
    "                print('[%d, %5d] loss: %.5f, train_accuracy: %.2f, time: %.2f' %(epoch + 1, i + 1, loss.item(), accuracy, t11-t00))\n",
    "        t1 = time.time()\n",
    "        total_time += t1 - t0\n",
    "        accuracy, loss = _evaluate_model(model, val_loader, device, criterion)\n",
    "        #print('duration:', t1-t0,'- train loss: ',avg_epoch_loss,' - train accuracy: ',avg_epoch_accuracy,' - validation accuracy: ', accuracy,' - validation loss: ', loss)\n",
    "        print('duration: %d s - train loss: %.5f - train accuracy: %.2f - validation loss: %.2f - validation accuracy: %.2f ' %(t1-t0, avg_epoch_loss, avg_epoch_accuracy, loss, accuracy))\n",
    "        train_loss_hist.append(avg_epoch_loss)\n",
    "        train_acc_hist.append(avg_epoch_accuracy)\n",
    "        val_loss_hist.append(loss)\n",
    "        val_acc_hist.append(accuracy)\n",
    "        data = {\n",
    "            'epoch': epoch+1,\n",
    "            'train_loss':avg_epoch_loss, \n",
    "            'train_accuracy':avg_epoch_accuracy,\n",
    "            'validation_loss':loss,\n",
    "            'validation_accuracy':accuracy,\n",
    "            'duration':total_time,\n",
    "            'criterion':criterion,\n",
    "            'optimizer':optimizer,\n",
    "            'method': 'standard',\n",
    "            'batchsize': len(next(iter(train_loader))[1])\n",
    "        }\n",
    "        \n",
    "        \n",
    "        if epoch%3==0 and evaluate_robustness == True:\n",
    "            (l_0_robustness, l_0_loss), (l_2_robustness, l_2_loss), (l_inf_robustness, l_inf_loss) = _evaluate_robustness(model, val_loader, device)\n",
    "            date['l_0_robustness'] = l_0_robustness\n",
    "            date['l_2_robustness'] = l_2_robustness\n",
    "            date['l_inf_robustness'] = l_inf_robustness\n",
    "        \n",
    "        train_stats = train_stats.append(data, ignore_index=True)\n",
    "        \n",
    "        if patience != None and patience < epoch and stop_early(val_loss_hist, patience) == True:\n",
    "            epochs_trained = i + 1\n",
    "            print('stopped early after', patience, 'epochs without decrease of validation loss')\n",
    "            break\n",
    "    print('Finished Training')\n",
    "    \n",
    "    return train_stats\n",
    "def _evaluate_model(model, data_loader, device, criterion):\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    acc_loss = 0.0\n",
    "    avg_loss = 0.0\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for i, data in enumerate(data_loader):\n",
    "            #print(i)\n",
    "            images, labels = data\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            if criterion != None:\n",
    "                loss = criterion(outputs, labels)\n",
    "                acc_loss += loss.item() \n",
    "                avg_loss = acc_loss / (i+1)\n",
    "            #print(outputs)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            #print(predicted)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    accuracy = 100 * correct / total\n",
    "    model.train()\n",
    "    return accuracy, avg_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class CifarResNet(tf.keras.Model):\n",
    "    def __init__(self):\n",
    "        super(CifarResNet, self).__init__()\n",
    "        self.conv1 = Conv2D(64, kernel_size=3,activation='relu', padding='same', strides=1)        \n",
    "        #self.pool1 = layers.MaxPool2D(pool_size=(3,3), strides=(2,2), padding='same')\n",
    "        \n",
    "        self.res_block1 = ResBlock(64, 64)\n",
    "        self.res_block3 = ResBlock(64, 64)\n",
    "        self.res_block4 = ResBlock(64, 128, 2)\n",
    "        self.res_block7 = ResBlock(128, 128)\n",
    "        self.res_block8 = ResBlock(128, 256, 2)\n",
    "        self.res_block13 = ResBlock(256, 256)\n",
    "        self.res_block14 = ResBlock(256 ,512, 2)\n",
    "        self.res_block16 = ResBlock(512, 512)\n",
    "        self.pool2 = layers.GlobalAveragePooling2D()\n",
    "        self.dense1 = Dense(10, activation='softmax')\n",
    "        \n",
    "    def call(self,inputs, training=False):\n",
    "        x = self.conv1(inputs)\n",
    "        x = self.res_block1(x)\n",
    "        x = self.res_block3(x)\n",
    "        x = self.res_block4(x)\n",
    "        x = self.res_block7(x)\n",
    "        x = self.res_block8(x)\n",
    "        x = self.res_block13(x)\n",
    "        x = self.res_block14(x)\n",
    "        x = self.res_block16(x)\n",
    "        x = self.pool2(x)\n",
    "        x = self.dense1(x)\n",
    "        return x\n",
    "    \n",
    "\n",
    "class ImagenetteResNet(tf.keras.Model):\n",
    "    def __init__(self):\n",
    "        super(ResNet, self).__init__()\n",
    "        self.conv1 = Conv2D(64, kernel_size=7,activation='relu', padding='same', strides=2)\n",
    "        self.pool1 = layers.MaxPool2D(pool_size=(3,3), strides=(2,2), padding='same')\n",
    "        \n",
    "        self.res_block1 = ResBlock(64, 64)\n",
    "        self.res_block3 = ResBlock(64, 64)\n",
    "        self.res_block4 = ResBlock(64, 128, 2)\n",
    "        self.res_block7 = ResBlock(128, 128)\n",
    "        self.res_block8 = ResBlock(128, 256, 2)\n",
    "        self.res_block13 = ResBlock(256, 256)\n",
    "        self.res_block14 = ResBlock(256 ,512, 2)\n",
    "        self.res_block16 = ResBlock(512, 512)\n",
    "        self.pool2 = layers.GlobalAveragePooling2D()\n",
    "        self.dense1 = Dense(10, activation='softmax')\n",
    "        \n",
    "    def call(self,inputs, training=False):\n",
    "        x = self.conv1(inputs)\n",
    "        x = self.pool1(x)\n",
    "        x = self.res_block1(x)\n",
    "        x = self.res_block3(x)\n",
    "        x = self.res_block4(x)\n",
    "        x = self.res_block7(x)\n",
    "        x = self.res_block8(x)\n",
    "        x = self.res_block13(x)\n",
    "        x = self.res_block14(x)\n",
    "        x = self.res_block16(x)\n",
    "        x = self.pool2(x)\n",
    "        x = self.dense1(x)\n",
    "        return x\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class ResBlock(tf.keras.layers.Layer):\n",
    "    def __init__(self, input_channels=3 ,output_channels = 64, stride=1, filter_size=3):\n",
    "        super(ResBlock, self).__init__()\n",
    "        self.stride = stride\n",
    "        self.conv1 = Conv2D(output_channels, 3, strides=self.stride, padding='same')\n",
    "        self.bn1 = layers.BatchNormalization()\n",
    "        self.conv2 = Conv2D(output_channels, 3, strides=1, padding='same')\n",
    "        self.bn2 = layers.BatchNormalization()\n",
    "        if stride == 2:\n",
    "            self.conv3 = Conv2D(output_channels, 1, strides=self.stride, padding='same')\n",
    "            self.bn3 = layers.BatchNormalization()\n",
    "        self.add1 = layers.Add()\n",
    "    \n",
    "    def call(self, inputs, training=False):\n",
    "        x = self.bn1(inputs, training=training)\n",
    "        x = tf.nn.relu(x)\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn2(x, training=training)\n",
    "        x = tf.nn.relu(x)\n",
    "        x = self.conv2(x)\n",
    "        #print(x.shape)\n",
    "        if self.stride == 2:\n",
    "            inputs = self.conv3(x)\n",
    "            inputs = self.bn3(x)\n",
    "        #print(inputs.shape)\n",
    "        return (self.add1([x, inputs]))\n",
    "\n",
    "    \n",
    "class std_conv(tf.keras.layers.Layer):\n",
    "    def __init__(self, filters_in, filters_out, strides=1, regulization=10, do=0):\n",
    "        super(std_conv, self).__init__()\n",
    "        self.conv = Conv2D(filters_out, 3, activation='relu', padding='same', strides=strides,kernel_regularizer=regularizers.l2(regulization))\n",
    "        self.do = Dropout(do)\n",
    "        self.bn = BatchNormalization()\n",
    "    def call(self, x, training):\n",
    "        x = self.conv(x)\n",
    "        x = self.bn(x, training)\n",
    "        x = self.do(x)\n",
    "        return x\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_m = CifarResNet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-04 09:20:21.593150: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7\n",
      "2021-10-04 09:20:22.388727: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 10), dtype=float32, numpy=\n",
       "array([[0.09670077, 0.11641659, 0.10450514, 0.09369759, 0.08706291,\n",
       "        0.11690781, 0.07528384, 0.10028592, 0.12022388, 0.0889155 ]],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_m(tf.random.uniform([1,224,224,3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function load_data.<locals>.normalize at 0x7fdf386bb4c0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Index'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function load_data.<locals>.normalize at 0x7fdf386bb4c0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Index'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <function load_data.<locals>.normalize at 0x7fdf386bb4c0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Index'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function load_data.<locals>.normalize at 0x7fdf10681ca0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Index'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function load_data.<locals>.normalize at 0x7fdf10681ca0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Index'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <function load_data.<locals>.normalize at 0x7fdf10681ca0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Index'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    }
   ],
   "source": [
    "ds_train, ds_test, _, _ = load_data(\"imagenette\", )\n",
    "ds_train, ds_test, _, _ = load_data(\"cifar10\", )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_m.compile(\n",
    "        loss=tf.keras.losses.SparseCategoricalCrossentropy() ,\n",
    "        optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3),\n",
    "        metrics=['accuracy'],\n",
    "        experimental_run_tf_function=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['cifar_res_net_2/res_block_18/conv2d_47/kernel:0', 'cifar_res_net_2/res_block_18/conv2d_47/bias:0', 'cifar_res_net_2/res_block_20/conv2d_52/kernel:0', 'cifar_res_net_2/res_block_20/conv2d_52/bias:0', 'cifar_res_net_2/res_block_22/conv2d_57/kernel:0', 'cifar_res_net_2/res_block_22/conv2d_57/bias:0'] when minimizing the loss.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['cifar_res_net_2/res_block_18/conv2d_47/kernel:0', 'cifar_res_net_2/res_block_18/conv2d_47/bias:0', 'cifar_res_net_2/res_block_20/conv2d_52/kernel:0', 'cifar_res_net_2/res_block_20/conv2d_52/bias:0', 'cifar_res_net_2/res_block_22/conv2d_57/kernel:0', 'cifar_res_net_2/res_block_22/conv2d_57/bias:0'] when minimizing the loss.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['cifar_res_net_2/res_block_18/conv2d_47/kernel:0', 'cifar_res_net_2/res_block_18/conv2d_47/bias:0', 'cifar_res_net_2/res_block_20/conv2d_52/kernel:0', 'cifar_res_net_2/res_block_20/conv2d_52/bias:0', 'cifar_res_net_2/res_block_22/conv2d_57/kernel:0', 'cifar_res_net_2/res_block_22/conv2d_57/bias:0'] when minimizing the loss.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['cifar_res_net_2/res_block_18/conv2d_47/kernel:0', 'cifar_res_net_2/res_block_18/conv2d_47/bias:0', 'cifar_res_net_2/res_block_20/conv2d_52/kernel:0', 'cifar_res_net_2/res_block_20/conv2d_52/bias:0', 'cifar_res_net_2/res_block_22/conv2d_57/kernel:0', 'cifar_res_net_2/res_block_22/conv2d_57/bias:0'] when minimizing the loss.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "98/98 [==============================] - 18s 163ms/step - loss: 5.6712 - accuracy: 0.1834 - val_loss: 3.4209 - val_accuracy: 0.0987\n",
      "Epoch 2/100\n",
      "98/98 [==============================] - 16s 159ms/step - loss: 1.7315 - accuracy: 0.3667 - val_loss: 3.7178 - val_accuracy: 0.1199\n",
      "Epoch 3/100\n",
      "98/98 [==============================] - 16s 159ms/step - loss: 1.4450 - accuracy: 0.4765 - val_loss: 2.6303 - val_accuracy: 0.1723\n",
      "Epoch 4/100\n",
      "98/98 [==============================] - 16s 160ms/step - loss: 1.3193 - accuracy: 0.5313 - val_loss: 2.4104 - val_accuracy: 0.3044\n",
      "Epoch 5/100\n",
      "98/98 [==============================] - 16s 160ms/step - loss: 1.1084 - accuracy: 0.6065 - val_loss: 2.0335 - val_accuracy: 0.3596\n",
      "Epoch 6/100\n",
      "98/98 [==============================] - 16s 160ms/step - loss: 1.0021 - accuracy: 0.6487 - val_loss: 1.6047 - val_accuracy: 0.4843\n",
      "Epoch 7/100\n",
      "98/98 [==============================] - 16s 160ms/step - loss: 0.9131 - accuracy: 0.6786 - val_loss: 1.1883 - val_accuracy: 0.6075\n",
      "Epoch 8/100\n",
      "98/98 [==============================] - 16s 160ms/step - loss: 0.7889 - accuracy: 0.7222 - val_loss: 1.0903 - val_accuracy: 0.6328\n",
      "Epoch 9/100\n",
      "98/98 [==============================] - 16s 160ms/step - loss: 0.7208 - accuracy: 0.7495 - val_loss: 1.4154 - val_accuracy: 0.5773\n",
      "Epoch 10/100\n",
      "98/98 [==============================] - 16s 160ms/step - loss: 0.6370 - accuracy: 0.7792 - val_loss: 1.2218 - val_accuracy: 0.6150\n",
      "Epoch 11/100\n",
      "98/98 [==============================] - 16s 160ms/step - loss: 0.6078 - accuracy: 0.7918 - val_loss: 1.4678 - val_accuracy: 0.6005\n",
      "Epoch 12/100\n",
      "98/98 [==============================] - 16s 160ms/step - loss: 0.5431 - accuracy: 0.8133 - val_loss: 1.1744 - val_accuracy: 0.6685\n",
      "Epoch 13/100\n",
      "98/98 [==============================] - 16s 160ms/step - loss: 0.4915 - accuracy: 0.8300 - val_loss: 0.9328 - val_accuracy: 0.7064\n",
      "Epoch 14/100\n",
      "98/98 [==============================] - 16s 160ms/step - loss: 0.4525 - accuracy: 0.8423 - val_loss: 0.8509 - val_accuracy: 0.7324\n",
      "Epoch 15/100\n",
      "98/98 [==============================] - 16s 160ms/step - loss: 0.4357 - accuracy: 0.8493 - val_loss: 0.9508 - val_accuracy: 0.7297\n",
      "Epoch 16/100\n",
      "98/98 [==============================] - 16s 160ms/step - loss: 0.4069 - accuracy: 0.8600 - val_loss: 0.8882 - val_accuracy: 0.7469\n",
      "Epoch 17/100\n",
      "98/98 [==============================] - 16s 160ms/step - loss: 0.3924 - accuracy: 0.8660 - val_loss: 1.2302 - val_accuracy: 0.6700\n",
      "Epoch 18/100\n",
      "98/98 [==============================] - 16s 160ms/step - loss: 0.3754 - accuracy: 0.8738 - val_loss: 0.7220 - val_accuracy: 0.7769\n",
      "Epoch 19/100\n",
      "98/98 [==============================] - 16s 160ms/step - loss: 0.3308 - accuracy: 0.8862 - val_loss: 0.5602 - val_accuracy: 0.8264\n",
      "Epoch 20/100\n",
      "98/98 [==============================] - 16s 160ms/step - loss: 0.3206 - accuracy: 0.8921 - val_loss: 0.6067 - val_accuracy: 0.8136\n",
      "Epoch 21/100\n",
      "98/98 [==============================] - 16s 160ms/step - loss: 0.3198 - accuracy: 0.8947 - val_loss: 0.7319 - val_accuracy: 0.7862\n",
      "Epoch 22/100\n",
      "98/98 [==============================] - 16s 160ms/step - loss: 0.2873 - accuracy: 0.9024 - val_loss: 0.8491 - val_accuracy: 0.7672\n",
      "Epoch 23/100\n",
      "98/98 [==============================] - 16s 160ms/step - loss: 0.2675 - accuracy: 0.9069 - val_loss: 0.8934 - val_accuracy: 0.7703\n",
      "Epoch 24/100\n",
      "98/98 [==============================] - 16s 160ms/step - loss: 0.2491 - accuracy: 0.9132 - val_loss: 0.8897 - val_accuracy: 0.7617\n",
      "Epoch 25/100\n",
      "98/98 [==============================] - 16s 160ms/step - loss: 0.2313 - accuracy: 0.9209 - val_loss: 0.5253 - val_accuracy: 0.8461\n",
      "Epoch 26/100\n",
      "98/98 [==============================] - 16s 160ms/step - loss: 0.2212 - accuracy: 0.9237 - val_loss: 0.9188 - val_accuracy: 0.7630\n",
      "Epoch 27/100\n",
      "98/98 [==============================] - 16s 160ms/step - loss: 0.2056 - accuracy: 0.9291 - val_loss: 0.9015 - val_accuracy: 0.7512\n",
      "Epoch 28/100\n",
      "98/98 [==============================] - 16s 160ms/step - loss: 0.2055 - accuracy: 0.9293 - val_loss: 0.6737 - val_accuracy: 0.8244\n",
      "Epoch 29/100\n",
      "98/98 [==============================] - 16s 160ms/step - loss: 0.1921 - accuracy: 0.9323 - val_loss: 0.5291 - val_accuracy: 0.8450\n",
      "Epoch 30/100\n",
      "98/98 [==============================] - 16s 160ms/step - loss: 0.1880 - accuracy: 0.9361 - val_loss: 0.7666 - val_accuracy: 0.7978\n",
      "Epoch 31/100\n",
      "98/98 [==============================] - 16s 160ms/step - loss: 0.1774 - accuracy: 0.9380 - val_loss: 0.7518 - val_accuracy: 0.8205\n",
      "Epoch 32/100\n",
      "98/98 [==============================] - 16s 160ms/step - loss: 0.1682 - accuracy: 0.9409 - val_loss: 0.5814 - val_accuracy: 0.8367\n",
      "Epoch 33/100\n",
      "98/98 [==============================] - 16s 160ms/step - loss: 0.1480 - accuracy: 0.9501 - val_loss: 0.5781 - val_accuracy: 0.8434\n",
      "Epoch 34/100\n",
      "98/98 [==============================] - 16s 160ms/step - loss: 0.1478 - accuracy: 0.9492 - val_loss: 0.6770 - val_accuracy: 0.8268\n",
      "Epoch 35/100\n",
      "98/98 [==============================] - 16s 160ms/step - loss: 0.1345 - accuracy: 0.9536 - val_loss: 0.5883 - val_accuracy: 0.8517\n",
      "Epoch 36/100\n",
      "98/98 [==============================] - 16s 160ms/step - loss: 0.1300 - accuracy: 0.9534 - val_loss: 0.6087 - val_accuracy: 0.8395\n",
      "Epoch 37/100\n",
      "98/98 [==============================] - 16s 160ms/step - loss: 0.1397 - accuracy: 0.9512 - val_loss: 0.5502 - val_accuracy: 0.8544\n",
      "Epoch 38/100\n",
      "98/98 [==============================] - 16s 160ms/step - loss: 0.1322 - accuracy: 0.9525 - val_loss: 0.5998 - val_accuracy: 0.8407\n",
      "Epoch 39/100\n",
      "98/98 [==============================] - 16s 160ms/step - loss: 0.1215 - accuracy: 0.9578 - val_loss: 0.4723 - val_accuracy: 0.8728\n",
      "Epoch 40/100\n",
      "98/98 [==============================] - 16s 160ms/step - loss: 0.1091 - accuracy: 0.9618 - val_loss: 0.6297 - val_accuracy: 0.8487\n",
      "Epoch 41/100\n",
      "98/98 [==============================] - 16s 160ms/step - loss: 0.1017 - accuracy: 0.9643 - val_loss: 0.6722 - val_accuracy: 0.8453\n",
      "Epoch 42/100\n",
      "98/98 [==============================] - 16s 160ms/step - loss: 0.0995 - accuracy: 0.9650 - val_loss: 0.6971 - val_accuracy: 0.8325\n",
      "Epoch 43/100\n",
      "98/98 [==============================] - 16s 160ms/step - loss: 0.0978 - accuracy: 0.9653 - val_loss: 0.5789 - val_accuracy: 0.8592\n",
      "Epoch 44/100\n",
      "98/98 [==============================] - 16s 160ms/step - loss: 0.0964 - accuracy: 0.9675 - val_loss: 0.5147 - val_accuracy: 0.8684\n",
      "Epoch 45/100\n",
      "98/98 [==============================] - 16s 160ms/step - loss: 0.0902 - accuracy: 0.9679 - val_loss: 0.7000 - val_accuracy: 0.8486\n",
      "Epoch 46/100\n",
      "98/98 [==============================] - 16s 160ms/step - loss: 0.0916 - accuracy: 0.9677 - val_loss: 0.7413 - val_accuracy: 0.8256\n",
      "Epoch 47/100\n",
      "98/98 [==============================] - 16s 160ms/step - loss: 0.0865 - accuracy: 0.9685 - val_loss: 0.7101 - val_accuracy: 0.8491\n",
      "Epoch 48/100\n",
      "98/98 [==============================] - 16s 160ms/step - loss: 0.0828 - accuracy: 0.9707 - val_loss: 0.7222 - val_accuracy: 0.8455\n",
      "Epoch 49/100\n",
      "98/98 [==============================] - 16s 160ms/step - loss: 0.0747 - accuracy: 0.9742 - val_loss: 0.6560 - val_accuracy: 0.8542\n",
      "Epoch 50/100\n",
      "98/98 [==============================] - 16s 160ms/step - loss: 0.0762 - accuracy: 0.9740 - val_loss: 0.5817 - val_accuracy: 0.8613\n",
      "Epoch 51/100\n",
      "98/98 [==============================] - 16s 160ms/step - loss: 0.0786 - accuracy: 0.9738 - val_loss: 0.6201 - val_accuracy: 0.8614\n",
      "Epoch 52/100\n",
      "98/98 [==============================] - 16s 160ms/step - loss: 0.0650 - accuracy: 0.9779 - val_loss: 0.5388 - val_accuracy: 0.8837\n",
      "Epoch 53/100\n",
      "98/98 [==============================] - 16s 160ms/step - loss: 0.0697 - accuracy: 0.9755 - val_loss: 0.5743 - val_accuracy: 0.8725\n",
      "Epoch 54/100\n",
      "98/98 [==============================] - 16s 160ms/step - loss: 0.0669 - accuracy: 0.9760 - val_loss: 0.4893 - val_accuracy: 0.8836\n",
      "Epoch 55/100\n",
      "98/98 [==============================] - 16s 160ms/step - loss: 0.0571 - accuracy: 0.9799 - val_loss: 0.7453 - val_accuracy: 0.8427\n",
      "Epoch 56/100\n",
      "98/98 [==============================] - 16s 160ms/step - loss: 0.0593 - accuracy: 0.9786 - val_loss: 0.5565 - val_accuracy: 0.8816\n",
      "Epoch 57/100\n",
      "98/98 [==============================] - 16s 160ms/step - loss: 0.0617 - accuracy: 0.9783 - val_loss: 0.5260 - val_accuracy: 0.8867\n",
      "Epoch 58/100\n",
      "98/98 [==============================] - 16s 160ms/step - loss: 0.0574 - accuracy: 0.9800 - val_loss: 0.6139 - val_accuracy: 0.8667\n",
      "Epoch 59/100\n",
      "98/98 [==============================] - 16s 160ms/step - loss: 0.0593 - accuracy: 0.9797 - val_loss: 0.5708 - val_accuracy: 0.8814\n",
      "Epoch 60/100\n",
      "98/98 [==============================] - 16s 160ms/step - loss: 0.0535 - accuracy: 0.9808 - val_loss: 0.5588 - val_accuracy: 0.8767\n",
      "Epoch 61/100\n",
      "98/98 [==============================] - 16s 160ms/step - loss: 0.0496 - accuracy: 0.9832 - val_loss: 0.5778 - val_accuracy: 0.8746\n",
      "Epoch 62/100\n",
      "98/98 [==============================] - 16s 160ms/step - loss: 0.0496 - accuracy: 0.9830 - val_loss: 1.3403 - val_accuracy: 0.7898\n",
      "Epoch 63/100\n",
      "98/98 [==============================] - 16s 160ms/step - loss: 0.0527 - accuracy: 0.9808 - val_loss: 0.7126 - val_accuracy: 0.8396\n",
      "Epoch 64/100\n",
      "98/98 [==============================] - 16s 160ms/step - loss: 0.0502 - accuracy: 0.9822 - val_loss: 0.9907 - val_accuracy: 0.8354\n",
      "Epoch 65/100\n",
      "98/98 [==============================] - 16s 160ms/step - loss: 0.0503 - accuracy: 0.9824 - val_loss: 0.6303 - val_accuracy: 0.8766\n",
      "Epoch 66/100\n",
      "98/98 [==============================] - 16s 160ms/step - loss: 0.0439 - accuracy: 0.9850 - val_loss: 0.5321 - val_accuracy: 0.8902\n",
      "Epoch 67/100\n",
      "98/98 [==============================] - 16s 160ms/step - loss: 0.0424 - accuracy: 0.9853 - val_loss: 0.6253 - val_accuracy: 0.8747\n",
      "Epoch 68/100\n",
      "98/98 [==============================] - 16s 160ms/step - loss: 0.0436 - accuracy: 0.9845 - val_loss: 0.6329 - val_accuracy: 0.8797\n",
      "Epoch 69/100\n",
      "98/98 [==============================] - 16s 160ms/step - loss: 0.0449 - accuracy: 0.9846 - val_loss: 0.6477 - val_accuracy: 0.8721\n",
      "Epoch 70/100\n",
      "98/98 [==============================] - 16s 160ms/step - loss: 0.0484 - accuracy: 0.9824 - val_loss: 0.6166 - val_accuracy: 0.8807\n",
      "Epoch 71/100\n",
      "98/98 [==============================] - 16s 160ms/step - loss: 0.0406 - accuracy: 0.9852 - val_loss: 0.7415 - val_accuracy: 0.8693\n",
      "Epoch 72/100\n",
      "98/98 [==============================] - 16s 160ms/step - loss: 0.0414 - accuracy: 0.9853 - val_loss: 0.5852 - val_accuracy: 0.8752\n",
      "Epoch 73/100\n",
      "98/98 [==============================] - 16s 160ms/step - loss: 0.0458 - accuracy: 0.9836 - val_loss: 0.7331 - val_accuracy: 0.8686\n",
      "Epoch 74/100\n",
      "98/98 [==============================] - 16s 160ms/step - loss: 0.0490 - accuracy: 0.9829 - val_loss: 0.6148 - val_accuracy: 0.8776\n",
      "Epoch 75/100\n",
      "98/98 [==============================] - 16s 160ms/step - loss: 0.0478 - accuracy: 0.9828 - val_loss: 0.6358 - val_accuracy: 0.8786\n",
      "Epoch 76/100\n",
      "98/98 [==============================] - 16s 160ms/step - loss: 0.0395 - accuracy: 0.9861 - val_loss: 0.5959 - val_accuracy: 0.8756\n",
      "Epoch 77/100\n",
      "98/98 [==============================] - 16s 160ms/step - loss: 0.0396 - accuracy: 0.9860 - val_loss: 0.6006 - val_accuracy: 0.8669\n",
      "Epoch 78/100\n",
      "98/98 [==============================] - 16s 160ms/step - loss: 0.0390 - accuracy: 0.9871 - val_loss: 0.7341 - val_accuracy: 0.8667\n",
      "Epoch 79/100\n",
      "98/98 [==============================] - 16s 160ms/step - loss: 0.0348 - accuracy: 0.9883 - val_loss: 0.5688 - val_accuracy: 0.8896\n",
      "Epoch 80/100\n",
      "98/98 [==============================] - 16s 160ms/step - loss: 0.0424 - accuracy: 0.9856 - val_loss: 0.7366 - val_accuracy: 0.8740\n",
      "Epoch 81/100\n",
      "98/98 [==============================] - 16s 160ms/step - loss: 0.0381 - accuracy: 0.9869 - val_loss: 0.6154 - val_accuracy: 0.8854\n",
      "Epoch 82/100\n",
      "98/98 [==============================] - 16s 160ms/step - loss: 0.0372 - accuracy: 0.9880 - val_loss: 0.5857 - val_accuracy: 0.8910\n",
      "Epoch 83/100\n",
      "98/98 [==============================] - 16s 160ms/step - loss: 0.0333 - accuracy: 0.9886 - val_loss: 0.5454 - val_accuracy: 0.8974\n",
      "Epoch 84/100\n",
      "98/98 [==============================] - 16s 160ms/step - loss: 0.0347 - accuracy: 0.9884 - val_loss: 0.5828 - val_accuracy: 0.8958\n",
      "Epoch 85/100\n",
      "98/98 [==============================] - 16s 160ms/step - loss: 0.0331 - accuracy: 0.9884 - val_loss: 0.9129 - val_accuracy: 0.8522\n",
      "Epoch 86/100\n",
      "98/98 [==============================] - 16s 160ms/step - loss: 0.0309 - accuracy: 0.9893 - val_loss: 0.8380 - val_accuracy: 0.8641\n",
      "Epoch 87/100\n",
      "98/98 [==============================] - 16s 160ms/step - loss: 0.0334 - accuracy: 0.9889 - val_loss: 0.6679 - val_accuracy: 0.8778\n",
      "Epoch 88/100\n",
      "98/98 [==============================] - 16s 160ms/step - loss: 0.0410 - accuracy: 0.9860 - val_loss: 0.5602 - val_accuracy: 0.8945\n",
      "Epoch 89/100\n",
      "98/98 [==============================] - 16s 160ms/step - loss: 0.0308 - accuracy: 0.9896 - val_loss: 0.6828 - val_accuracy: 0.8777\n",
      "Epoch 90/100\n",
      "98/98 [==============================] - 16s 160ms/step - loss: 0.0307 - accuracy: 0.9898 - val_loss: 0.7848 - val_accuracy: 0.8788\n",
      "Epoch 91/100\n",
      "98/98 [==============================] - 16s 160ms/step - loss: 0.0346 - accuracy: 0.9882 - val_loss: 0.7143 - val_accuracy: 0.8751\n",
      "Epoch 92/100\n",
      "98/98 [==============================] - 16s 160ms/step - loss: 0.0258 - accuracy: 0.9907 - val_loss: 0.5702 - val_accuracy: 0.8999\n",
      "Epoch 93/100\n",
      "98/98 [==============================] - 16s 160ms/step - loss: 0.0299 - accuracy: 0.9896 - val_loss: 0.6357 - val_accuracy: 0.8892\n",
      "Epoch 94/100\n",
      "98/98 [==============================] - 16s 160ms/step - loss: 0.0363 - accuracy: 0.9877 - val_loss: 0.5656 - val_accuracy: 0.8978\n",
      "Epoch 95/100\n",
      "98/98 [==============================] - 16s 160ms/step - loss: 0.0300 - accuracy: 0.9895 - val_loss: 0.6946 - val_accuracy: 0.8840\n",
      "Epoch 96/100\n",
      "98/98 [==============================] - 16s 160ms/step - loss: 0.0269 - accuracy: 0.9914 - val_loss: 0.8353 - val_accuracy: 0.8672\n",
      "Epoch 97/100\n",
      "98/98 [==============================] - 16s 160ms/step - loss: 0.0301 - accuracy: 0.9897 - val_loss: 0.7821 - val_accuracy: 0.8702\n",
      "Epoch 98/100\n",
      "98/98 [==============================] - 16s 160ms/step - loss: 0.0287 - accuracy: 0.9901 - val_loss: 0.6807 - val_accuracy: 0.8840\n",
      "Epoch 99/100\n",
      "98/98 [==============================] - 16s 160ms/step - loss: 0.0264 - accuracy: 0.9908 - val_loss: 0.6622 - val_accuracy: 0.8905\n",
      "Epoch 100/100\n",
      "98/98 [==============================] - 16s 160ms/step - loss: 0.0215 - accuracy: 0.9926 - val_loss: 0.6001 - val_accuracy: 0.8880\n",
      "CPU times: user 27min 58s, sys: 1min 27s, total: 29min 25s\n",
      "Wall time: 26min 16s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "hist = tf_m.fit(\n",
    "    x=ds_train,\n",
    "    epochs=100,\n",
    "    validation_data=ds_test,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def load_data(dataset,ratio='100%'):\n",
    "\n",
    "    def augment(image,label):\n",
    "        #image = tf.image.convert_image_dtype(image, tf.float32)\n",
    "        #image = tf.image.rot90(image, tf.random.uniform(shape=[], minval=0, maxval=4, dtype=tf.int32)) # random rotation\n",
    "        image = tf.image.random_flip_left_right(image)\n",
    "        #image = tf.image.random_flip_up_down(image)\n",
    "        #image = tf.image.random_hue(image, 0.08)\n",
    "        #image = tf.image.random_saturation(image, 0.6, 1.6)\n",
    "        #image = tf.image.random_contrast(image, 0.7, 1.3)\n",
    "        #image = tf.image.random_brightness(image, max_delta=0.5) # Random brightness\n",
    "        image = tf.image.resize_with_crop_or_pad(image, 224+60, 224+60) # Add 60 pixels of padding\n",
    "        image = tf.image.random_crop(image, size=[224,224,3]) # Random crop back to 28x28\n",
    "        return image,label\n",
    "    \n",
    "    def cifar_augment(image,label):\n",
    "        image = tf.image.random_flip_left_right(image)\n",
    "        image = tf.image.resize_with_crop_or_pad(image, 32+6, 32+6)\n",
    "        image = tf.image.random_crop(image, size=[32,32,3])\n",
    "        return image,label\n",
    "    \n",
    "    @tf.function\n",
    "    def load_image(datapoint):\n",
    "        input_image, label = normalize(datapoint)\n",
    "        return input_image, label\n",
    "\n",
    "    \n",
    "    if dataset=='cifar10':\n",
    "        ds, info = tfds.load(name=dataset, with_info=True, split=[f\"train[:{ratio}]\",f\"test[:{ratio}]\"])\n",
    "        ds_train=ds[0]\n",
    "        ds_test=ds[1]\n",
    "        def normalize(x):\n",
    "            y = {'image': tf.image.convert_image_dtype(x['image'], tf.float32), 'label': x['label']}\n",
    "            y = (tf.image.resize(y['image'], (32,32)), y['label'])\n",
    "            return y\n",
    "        num_train_examples= info.splits['train'].num_examples\n",
    "        BATCH_SIZE = 512\n",
    "\n",
    "        ds_train = (\n",
    "            ds_train\n",
    "            .map(normalize, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "            .take(num_train_examples)\n",
    "            .cache()\n",
    "            .shuffle(num_train_examples)\n",
    "            .map(cifar_augment, num_parallel_calls=AUTOTUNE)\n",
    "            .batch(BATCH_SIZE)\n",
    "            .prefetch(AUTOTUNE)\n",
    "        ) \n",
    "\n",
    "        ds_test = ds_test.map(\n",
    "            normalize, )\n",
    "        ds_test = ds_test.batch(BATCH_SIZE)\n",
    "        ds_test = ds_test.cache()\n",
    "        ds_test = ds_test.prefetch(tf.data.experimental.AUTOTUNE)\n",
    "\n",
    "\n",
    "\n",
    "        attack_set = list(ds[1].map(load_image))[:1000]\n",
    "\n",
    "        attack_images = tf.convert_to_tensor([sample[0] for sample in attack_set])\n",
    "        attack_labels = tf.convert_to_tensor([sample[1] for sample in attack_set])\n",
    "        return ds_train, ds_test, attack_images, attack_labels\n",
    "    \n",
    "    \n",
    "    if dataset=='imagenette':\n",
    "        ds, info = tfds.load(name=dataset, with_info=True, split=[f\"train[:{ratio}]\",f\"validation[:{ratio}]\"])\n",
    "        \n",
    "        ds_train=ds[0]\n",
    "        ds_test=ds[1]\n",
    "        def normalize(x):\n",
    "            y = {'image': tf.image.convert_image_dtype(x['image'], tf.float32), 'label': x['label']}\n",
    "            y = (tf.image.resize(y['image'], (224,224)), y['label'])\n",
    "            return y\n",
    "\n",
    "\n",
    "        num_train_examples= info.splits['train'].num_examples\n",
    "        BATCH_SIZE = 128\n",
    "\n",
    "        ds_train = (\n",
    "            ds_train\n",
    "            .map(normalize, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "            .take(num_train_examples)\n",
    "            .cache()\n",
    "            .shuffle(num_train_examples)\n",
    "            .map(augment, num_parallel_calls=AUTOTUNE)\n",
    "            .batch(BATCH_SIZE)\n",
    "            .prefetch(AUTOTUNE)\n",
    "        ) \n",
    "\n",
    "        ds_test = ds_test.map(\n",
    "            normalize, )\n",
    "        ds_test = ds_test.batch(BATCH_SIZE)\n",
    "        ds_test = ds_test.cache()\n",
    "        ds_test = ds_test.prefetch(tf.data.experimental.AUTOTUNE)\n",
    "\n",
    "\n",
    "\n",
    "        attack_set = list(ds[1].map(load_image))[:256]\n",
    "\n",
    "        attack_images = tf.convert_to_tensor([sample[0] for sample in attack_set])\n",
    "        attack_labels = tf.convert_to_tensor([sample[1] for sample in attack_set])\n",
    "\n",
    "        return ds_train, ds_test, attack_images, attack_labels\n",
    "    \n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
